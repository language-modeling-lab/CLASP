{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T02:33:09.907414Z",
     "iopub.status.busy": "2024-10-31T02:33:09.906637Z",
     "iopub.status.idle": "2024-10-31T02:33:36.074255Z",
     "shell.execute_reply": "2024-10-31T02:33:36.072901Z",
     "shell.execute_reply.started": "2024-10-31T02:33:09.907366Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /opt/conda/lib/python3.10/site-packages (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.12.2)\n",
      "Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2023.7.22)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: sentence_transformers in /opt/conda/lib/python3.10/site-packages (3.2.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.46.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.0.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.11.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.26.2)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (9.5.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2023.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.6.3)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.23.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2023.6.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.20.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.20.0->sentence_transformers) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown\n",
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T02:33:36.077088Z",
     "iopub.status.busy": "2024-10-31T02:33:36.076724Z",
     "iopub.status.idle": "2024-10-31T02:33:42.250029Z",
     "shell.execute_reply": "2024-10-31T02:33:42.249013Z",
     "shell.execute_reply.started": "2024-10-31T02:33:36.077055Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import pandas as pd\n",
    "import gc\n",
    "import random\n",
    "import pickle\n",
    "import gdown\n",
    "import json\n",
    "import string\n",
    "from zipfile import ZipFile\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T02:33:42.251805Z",
     "iopub.status.busy": "2024-10-31T02:33:42.251315Z",
     "iopub.status.idle": "2024-10-31T02:33:42.319764Z",
     "shell.execute_reply": "2024-10-31T02:33:42.318776Z",
     "shell.execute_reply.started": "2024-10-31T02:33:42.251776Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T22:34:51.031008Z",
     "iopub.status.busy": "2023-10-31T22:34:51.030594Z",
     "iopub.status.idle": "2023-10-31T22:35:18.533463Z",
     "shell.execute_reply": "2023-10-31T22:35:18.532411Z",
     "shell.execute_reply.started": "2023-10-31T22:34:51.030974Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "url = \"https://drive.google.com/file/d/1PwoBj4Fv4qDIaEq75tydQ67XaUC36eAF/view?usp=drive_link\"\n",
    "output = \"total_dataset_v5.pkl\"\n",
    "gdown.download(url, output, quiet=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T03:10:10.016575Z",
     "iopub.status.busy": "2023-11-15T03:10:10.016159Z",
     "iopub.status.idle": "2023-11-15T03:10:13.833978Z",
     "shell.execute_reply": "2023-11-15T03:10:13.833085Z",
     "shell.execute_reply.started": "2023-11-15T03:10:10.016542Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "url = 'https://drive.google.com/file/d/1kPpC2Hyy4H0adWbzbQpb6UbJZ2Au_APF/view?usp=sharing'\n",
    "output = \"lasp_concoat.pt\"\n",
    "gdown.download(url, output, quiet=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T03:23:55.966026Z",
     "iopub.status.busy": "2023-11-15T03:23:55.965704Z",
     "iopub.status.idle": "2023-11-15T03:23:56.721416Z",
     "shell.execute_reply": "2023-11-15T03:23:56.720372Z",
     "shell.execute_reply.started": "2023-11-15T03:23:55.965998Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "url = 'https://drive.google.com/file/d/15y2oFmuRX_OWvEDvmeyQMoHkAxJlx6AC/view?usp=sharing'\n",
    "output = \"lasp_gating.pt\"\n",
    "gdown.download(url, output, quiet=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-01T04:19:19.716983Z",
     "iopub.status.busy": "2023-11-01T04:19:19.716507Z",
     "iopub.status.idle": "2023-11-01T04:19:37.217578Z",
     "shell.execute_reply": "2023-11-01T04:19:37.216271Z",
     "shell.execute_reply.started": "2023-11-01T04:19:19.716945Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open('total_dataset_v5.pkl', 'rb') as f:\n",
    "    total_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T16:57:23.055368Z",
     "iopub.status.busy": "2024-10-29T16:57:23.054882Z",
     "iopub.status.idle": "2024-10-29T16:57:23.566944Z",
     "shell.execute_reply": "2024-10-29T16:57:23.565814Z",
     "shell.execute_reply.started": "2024-10-29T16:57:23.055329Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "total_dataset['train'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T14:51:36.190382Z",
     "iopub.status.busy": "2023-12-19T14:51:36.190111Z",
     "iopub.status.idle": "2023-12-19T14:52:05.044766Z",
     "shell.execute_reply": "2023-12-19T14:52:05.043911Z",
     "shell.execute_reply.started": "2023-12-19T14:51:36.190359Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1PwoBj4Fv4qDIaEq75tydQ67XaUC36eAF\n",
      "From (redirected): https://drive.google.com/uc?id=1PwoBj4Fv4qDIaEq75tydQ67XaUC36eAF&confirm=t&uuid=5aa2dbe2-6370-4455-bacb-2dbf5ebec878\n",
      "To: /kaggle/working/total_dataset_v11.pkl\n",
      "100%|██████████| 2.18G/2.18G [00:27<00:00, 78.7MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'total_dataset_v11.pkl'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://drive.google.com/file/d/1PwoBj4Fv4qDIaEq75tydQ67XaUC36eAF/view?usp=sharing\"\n",
    "output = \"total_dataset_v11.pkl\"\n",
    "gdown.download(url, output, quiet=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T02:33:42.322335Z",
     "iopub.status.busy": "2024-10-31T02:33:42.321984Z",
     "iopub.status.idle": "2024-10-31T02:34:50.308267Z",
     "shell.execute_reply": "2024-10-31T02:34:50.305272Z",
     "shell.execute_reply.started": "2024-10-31T02:33:42.322307Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open('total_dataset_v11.pkl', 'rb') as f:\n",
    "    total_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T23:58:45.272329Z",
     "iopub.status.busy": "2023-12-19T23:58:45.272038Z",
     "iopub.status.idle": "2023-12-19T23:58:45.318203Z",
     "shell.execute_reply": "2023-12-19T23:58:45.317265Z",
     "shell.execute_reply.started": "2023-12-19T23:58:45.272298Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['audio', 'text', 'image', 'xlmr-emb', 'hubert-emb', 'pure-text', 'id', 'source', 'audio_path'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_dataset['train'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T17:09:34.680255Z",
     "iopub.status.busy": "2024-10-29T17:09:34.679881Z",
     "iopub.status.idle": "2024-10-29T17:09:34.690989Z",
     "shell.execute_reply": "2024-10-29T17:09:34.689992Z",
     "shell.execute_reply.started": "2024-10-29T17:09:34.680224Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class HubertLabseConcat(nn.Module):\n",
    "    def __init__(self, in_features_text, in_features_image):\n",
    "        super(HubertLabseConcat, self).__init__()\n",
    "        self.image_seq = nn.Sequential(\n",
    "            nn.Linear(in_features_image, 768),\n",
    "            nn.BatchNorm1d(768),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.15),\n",
    "            nn.Linear(768, 576),\n",
    "            nn.BatchNorm1d(576),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(576, 768),\n",
    "        )\n",
    "        self.audio_seq = nn.Sequential(\n",
    "            nn.Linear(in_features_text, 768),\n",
    "            nn.BatchNorm1d(768),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.15),\n",
    "            nn.Linear(768, 576),\n",
    "            nn.BatchNorm1d(576),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(576, 768),\n",
    "        )\n",
    "        \n",
    "        self.mix_seq = nn.Sequential(\n",
    "            nn.Linear(2 * 768, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(1024, 800),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(800, 768),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x_audio, x_image):\n",
    "        x1 = self.audio_seq(x_audio)\n",
    "        x2 = self.image_seq(x_image)\n",
    "        concats = torch.cat((x1, x2), dim=1)\n",
    "        x = self.mix_seq(concats)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T14:53:06.176923Z",
     "iopub.status.busy": "2023-12-19T14:53:06.176507Z",
     "iopub.status.idle": "2023-12-19T14:53:06.224097Z",
     "shell.execute_reply": "2023-12-19T14:53:06.223020Z",
     "shell.execute_reply.started": "2023-12-19T14:53:06.176894Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class HubertLabseConcat(nn.Module):\n",
    "    def __init__(self, in_features_text, in_features_image, mode = 'joint'):\n",
    "        super(HubertLabseConcat, self).__init__()\n",
    "        self.mode = mode\n",
    "        self.image_seq = nn.Sequential(\n",
    "            nn.Linear(in_features_image, 768),\n",
    "            nn.BatchNorm1d(768),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.15),\n",
    "            nn.Linear(768, 576),\n",
    "            nn.BatchNorm1d(576),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(576, 768),\n",
    "        )\n",
    "        self.audio_seq = nn.Sequential(\n",
    "            nn.Linear(in_features_text, 768),\n",
    "            nn.BatchNorm1d(768),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.15),\n",
    "            nn.Linear(768, 576),\n",
    "            nn.BatchNorm1d(576),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(576, 768),\n",
    "        )\n",
    "        \n",
    "        self.mix_seq = nn.Sequential(\n",
    "            nn.Linear(2 * 768, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(1024, 800),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(800, 768),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x_audio, x_image):\n",
    "        x1 = self.audio_seq(x_audio)\n",
    "        if self.mode == 'audio':\n",
    "            return x1\n",
    "        x2 = self.image_seq(x_image)\n",
    "        if self.mode == 'image':\n",
    "            return x2\n",
    "        concats = torch.cat((x1, x2), dim=1)\n",
    "        x = self.mix_seq(concats)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T14:53:06.225743Z",
     "iopub.status.busy": "2023-12-19T14:53:06.225380Z",
     "iopub.status.idle": "2023-12-19T14:53:06.242491Z",
     "shell.execute_reply": "2023-12-19T14:53:06.241698Z",
     "shell.execute_reply.started": "2023-12-19T14:53:06.225710Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Wav2vecConcat(nn.Module):\n",
    "    def __init__(self, in_features_text, in_features_image):\n",
    "        super(Wav2vecConcat, self).__init__()\n",
    "        self.image_seq = nn.Sequential(\n",
    "            nn.Linear(in_features_image, 768),\n",
    "            nn.BatchNorm1d(768),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.15),\n",
    "            nn.Linear(768, 576),\n",
    "            nn.BatchNorm1d(576),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(576, 768),\n",
    "        )\n",
    "        self.audio_seq = nn.Sequential(\n",
    "            nn.Linear(in_features_text, 700),\n",
    "            nn.BatchNorm1d(700),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.15),\n",
    "            nn.Linear(700, 576),\n",
    "            nn.BatchNorm1d(576),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(576, 768),\n",
    "        )\n",
    "        \n",
    "        self.mix_seq = nn.Sequential(\n",
    "            nn.Linear(2 * in_features_text, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(1024, 800),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(800, in_features_text),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x_audio, x_image):\n",
    "        x1 = self.audio_seq(x_audio)\n",
    "        x2 = self.image_seq(x_image)\n",
    "        concats = torch.cat((x1, x2), dim=1)\n",
    "        x = self.mix_seq(concats)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T14:53:06.244470Z",
     "iopub.status.busy": "2023-12-19T14:53:06.243851Z",
     "iopub.status.idle": "2023-12-19T14:53:06.259879Z",
     "shell.execute_reply": "2023-12-19T14:53:06.259076Z",
     "shell.execute_reply.started": "2023-12-19T14:53:06.244436Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class HubertLabseGating(nn.Module):\n",
    "    def __init__(self, in_features_text, in_features_image):\n",
    "        super(HubertLabseGating, self).__init__()\n",
    "        self.image_seq = nn.Sequential(\n",
    "            nn.Linear(in_features_image, 768),\n",
    "            nn.BatchNorm1d(768),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.15),\n",
    "            nn.Linear(768, 576),\n",
    "            nn.BatchNorm1d(576),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(576, 768),\n",
    "        )\n",
    "        self.text_seq = nn.Sequential(\n",
    "            nn.Linear(in_features_text, 768),\n",
    "            nn.BatchNorm1d(768),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.15),\n",
    "            nn.Linear(768, 576),\n",
    "            nn.BatchNorm1d(576),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(576, 768),\n",
    "        )\n",
    "        \n",
    "        # Input gate\n",
    "        self.input_gate_text = nn.Sequential(\n",
    "            nn.Linear(768, 768),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.input_gate_image = nn.Sequential(\n",
    "            nn.Linear(768, 768),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Forget gate\n",
    "        self.forget_gate_text = nn.Sequential(\n",
    "            nn.Linear(768, 768),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.forget_gate_image = nn.Sequential(\n",
    "            nn.Linear(768, 768),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Tanh function for new cell state computation\n",
    "        self.tanh_text = nn.Sequential(\n",
    "            nn.Linear(768, 768),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.tanh_image = nn.Sequential(\n",
    "            nn.Linear(768, 768),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        # Weighting mechanism for final embedding computation\n",
    "        self.weight = nn.Sequential(\n",
    "            nn.Linear(768 * 2, 768 * 2)\n",
    "        )\n",
    "\n",
    "        \n",
    "    def forward(self, x_text, x_image):\n",
    "        x1 = self.text_seq(x_text)\n",
    "        x2 = self.image_seq(x_image)\n",
    "        \n",
    "        # Apply input gate\n",
    "        input_gate_text = self.input_gate_text(x1)\n",
    "        input_gate_image = self.input_gate_image(x2)\n",
    "        \n",
    "        # Apply forget gate\n",
    "        forget_gate_text = self.forget_gate_text(x1)\n",
    "        forget_gate_image = self.forget_gate_image(x2)\n",
    "        \n",
    "        # Compute new cell state using tanh function\n",
    "        new_cell_state_text = self.tanh_text(x1)\n",
    "        new_cell_state_image = self.tanh_image(x2)\n",
    "        \n",
    "        # Update cell state using input and forget gates\n",
    "        x1 = input_gate_text * new_cell_state_text + forget_gate_text * x1\n",
    "        x2 = input_gate_image * new_cell_state_image + forget_gate_image * x2\n",
    "        \n",
    "        # Compute weighted average of updated cell states\n",
    "        weight = torch.softmax(self.weight(torch.cat((x1, x2), dim=-1)), dim=-1)\n",
    "        x = weight[:, :768] * x1 + weight[:, 768:] * x2\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T23:58:45.333605Z",
     "iopub.status.busy": "2023-12-19T23:58:45.333219Z",
     "iopub.status.idle": "2023-12-19T23:58:45.360431Z",
     "shell.execute_reply": "2023-12-19T23:58:45.359496Z",
     "shell.execute_reply.started": "2023-12-19T23:58:45.333572Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_the_model(model, train_dataloader, val_dataloader, model_path_save, num_epochs=100, learning_rate=5e-6, delta=0.6, temperature=np.log(0.07)):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    def eval_epoch(model: nn.Module, dataloader: torch.utils.data.DataLoader, test_mode=False):\n",
    "        eval_loss = 0\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad(), tqdm(enumerate(dataloader), total=len(dataloader)) as pbar:\n",
    "            for i, (text_emb, audio_emb, image_emb) in pbar:\n",
    "                text_emb = text_emb.to(device)\n",
    "                audio_emb = audio_emb.to(device)\n",
    "                image_emb = image_emb.to(device)\n",
    "\n",
    "                final_emb = model(audio_emb, image_emb)\n",
    "\n",
    "                # L2 normalize the embeddings\n",
    "                final_emb = l2_normalize(final_emb)\n",
    "                text_emb = l2_normalize(text_emb)\n",
    "\n",
    "                # Compute similarity matrix\n",
    "                sim_matrix = torch.matmul(final_emb, text_emb.t())\n",
    "                \n",
    "                # Scale similarity matrix by temperature\n",
    "                temperature_tensor = torch.tensor(temperature).to(device)\n",
    "                sim_matrix *= torch.exp(temperature_tensor)\n",
    "\n",
    "                # Compute contrastive loss\n",
    "                labels = torch.arange(sim_matrix.size(0)).to(device)\n",
    "                loss = (nn.CrossEntropyLoss()(sim_matrix, labels) + nn.CrossEntropyLoss()(sim_matrix.t(), labels)) / 2\n",
    "\n",
    "                eval_loss += loss.item()\n",
    "\n",
    "                discription = 'Validation' if not test_mode else 'Test'\n",
    "                pbar.set_description(f'{discription} Loss: {loss.item():.4f}')\n",
    "        return eval_loss\n",
    "\n",
    "    def l2_normalize(x, dim=-1):\n",
    "        return x / x.norm(2, dim=dim, keepdim=True)\n",
    "    \n",
    "    def train_epoch(model: nn.Module, optimizer: torch.optim.Optimizer, dataloader: torch.utils.data.DataLoader, temperature):\n",
    "        train_loss = 0\n",
    "        model.train()\n",
    "        with tqdm(enumerate(train_loader), total=len(train_loader)) as pbar:\n",
    "            for i, (text_emb, audio_emb, image_emb) in pbar:\n",
    "                \n",
    "                text_emb = text_emb.to(device)\n",
    "                audio_emb = audio_emb.to(device)\n",
    "                image_emb = image_emb.to(device)\n",
    "\n",
    "                final_emb = model(audio_emb, image_emb)\n",
    "\n",
    "                # L2 normalize the embeddings\n",
    "                final_emb = l2_normalize(final_emb)\n",
    "                text_emb = l2_normalize(text_emb)\n",
    "\n",
    "                # Compute similarity matrix\n",
    "                sim_matrix = torch.matmul(final_emb, text_emb.t())\n",
    "                \n",
    "                # Scale similarity matrix by temperature\n",
    "                temperature_tensor = torch.tensor(temperature).to(device)\n",
    "                sim_matrix *= torch.exp(temperature_tensor)\n",
    "\n",
    "                # Compute contrastive loss\n",
    "                labels = torch.arange(sim_matrix.size(0)).to(device)\n",
    "                loss = (nn.CrossEntropyLoss()(sim_matrix, labels) + nn.CrossEntropyLoss()(sim_matrix.t(), labels)) / 2\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "\n",
    "                pbar.set_description(f'Train Loss: {loss.item():.4f}')\n",
    "\n",
    "        return train_loss\n",
    "    \n",
    "\n",
    "    def train(model: nn.Module, optimizer: torch.optim.Optimizer, train_dataloader: torch.utils.data.DataLoader, val_dataloader: torch.utils.data.DataLoader, model_path_save, epochs: int, temperature, patience=10):\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        best_val_loss = float('inf')\n",
    "        counter = 0\n",
    "        epoch_num = num_epochs\n",
    "        best_model = None\n",
    "\n",
    "        # Define the learning rate scheduler\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.4)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.ipc_collect()\n",
    "            start_time = time()\n",
    "\n",
    "            train_loss = train_epoch(model, optimizer, train_dataloader, temperature)\n",
    "            val_loss = eval_epoch(model, val_dataloader, temperature)\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "            end_time = time()\n",
    "\n",
    "            print(f'Epoch {epoch + 1} finished in {end_time - start_time:.2f}s')\n",
    "            print(f\"[Epoch {epoch + 1}]\\t\"\n",
    "                f\"Train Loss: {train_loss:.6f}\\t\"\n",
    "                f\"Validation Loss: {val_loss:.6f}\")\n",
    "\n",
    "            # Check if the validation loss has improved\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model = deepcopy(model)\n",
    "                counter = 0\n",
    "            else:\n",
    "                counter += 1\n",
    "\n",
    "            # If the validation loss didn't improve for 'patience' epochs, stop the training\n",
    "            if counter >= patience:\n",
    "                print(f'Early stopping after {patience} epochs without improvement in validation loss.')\n",
    "                with open('stopped_epoch.txt', 'w') as f:\n",
    "                    print(f'Stopped at epoch: {epoch + 1}')\n",
    "                    f.write(f'Stopped at epoch: {epoch + 1}\\n')\n",
    "                    torch.save(best_model, model_path_save)\n",
    "                    epoch_num = epoch + 1\n",
    "                break\n",
    "\n",
    "            # Step the learning rate scheduler\n",
    "            scheduler.step()\n",
    "\n",
    "        return train_losses, val_losses, epoch_num, best_model\n",
    "\n",
    "    \n",
    "    def plot_loss(loss, num_epochs, label):\n",
    "        ls_epoch = [_ + 1 for _ in range(epoch_num)]\n",
    "        plt.plot(ls_epoch, loss, color='r', label=label)\n",
    "        plt.title('Loss plot')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    train_losses, val_losses, epoch_num, best_model = train(model, optimizer, train_dataloader, val_dataloader, model_path_save, num_epochs, temperature)\n",
    "    plot_loss(train_losses, epoch_num, 'train')\n",
    "    plot_loss(val_losses, epoch_num, 'validation')\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T10:53:56.357581Z",
     "iopub.status.busy": "2023-12-19T10:53:56.357232Z",
     "iopub.status.idle": "2023-12-19T10:53:56.363452Z",
     "shell.execute_reply": "2023-12-19T10:53:56.362482Z",
     "shell.execute_reply.started": "2023-12-19T10:53:56.357553Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped at epoch: 107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('stopped_epoch.txt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T12:49:52.699853Z",
     "iopub.status.busy": "2024-10-27T12:49:52.699392Z",
     "iopub.status.idle": "2024-10-27T12:49:52.758549Z",
     "shell.execute_reply": "2024-10-27T12:49:52.757450Z",
     "shell.execute_reply.started": "2024-10-27T12:49:52.699824Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CusDataset(Dataset):\n",
    "    def __init__(self, dataset, audio_name, text_name):\n",
    "        self.dataset = dataset\n",
    "        self.text_name = text_name\n",
    "        self.audio_name = audio_name\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset[self.audio_name])\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.dataset[self.text_name][i], self.dataset[self.audio_name][i], self.dataset['image'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=CusDataset(total_dataset['train'], 'hubert-emb', 'text'), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(dataset=CusDataset(total_dataset['validation'], 'hubert-emb', 'text'), batch_size=16, shuffle=False)\n",
    "hubert_labse_model = HubertLabseConcat(1024, 1000).to(device)\n",
    "hubert_labse_model = train_the_model(hubert_labse_model, train_loader, val_loader, num_epochs=400, temperature=float(np.log(0.07)))\n",
    "torch.save(hubert_labse_model, 'es_models/hubert_labse_concat_es.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T23:19:31.566505Z",
     "iopub.status.busy": "2023-12-19T23:19:31.566146Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.3567: 100%|██████████| 2853/2853 [00:19<00:00, 147.77it/s]\n",
      "Test Loss: 1.3637: 100%|██████████| 714/714 [00:02<00:00, 345.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 finished in 21.38s\n",
      "[Epoch 1]\tTrain Loss: 9762.914602\tValidation Loss: 1950.041477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.3562: 100%|██████████| 2853/2853 [00:19<00:00, 146.32it/s]\n",
      "Test Loss: 1.3637: 100%|██████████| 714/714 [00:02<00:00, 353.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 finished in 21.53s\n",
      "[Epoch 2]\tTrain Loss: 9762.780412\tValidation Loss: 1949.998144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.3578: 100%|██████████| 2853/2853 [00:19<00:00, 146.17it/s]\n",
      "Test Loss: 1.3634: 100%|██████████| 714/714 [00:02<00:00, 352.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 finished in 21.55s\n",
      "[Epoch 3]\tTrain Loss: 9762.796779\tValidation Loss: 1949.952221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.3569: 100%|██████████| 2853/2853 [00:19<00:00, 145.98it/s]\n",
      "Test Loss: 1.3635: 100%|██████████| 714/714 [00:02<00:00, 350.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 finished in 21.59s\n",
      "[Epoch 4]\tTrain Loss: 9762.779109\tValidation Loss: 1949.970239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.4219:  44%|████▎     | 1246/2853 [00:08<00:10, 147.76it/s]"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(dataset=CusDataset(total_dataset['train'], 'hubert-emb', 'text'), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(dataset=CusDataset(total_dataset['validation'], 'hubert-emb', 'text'), batch_size=16, shuffle=False)\n",
    "hubert_labse_model = torch.load('hubert_labse_model_v3.pt')\n",
    "hubert_labse_model = train_the_model(hubert_labse_model, train_loader, val_loader, 'hubert_labse_model_es.pt', num_epochs=400, temperature=float(np.log(0.07)), learning_rate=1e-7)\n",
    "torch.save(hubert_labse_model, 'hubert_labse_model_es.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T22:39:37.099697Z",
     "iopub.status.busy": "2023-12-19T22:39:37.099030Z",
     "iopub.status.idle": "2023-12-19T22:43:47.371302Z",
     "shell.execute_reply": "2023-12-19T22:43:47.370291Z",
     "shell.execute_reply.started": "2023-12-19T22:39:37.099658Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=CusDataset(total_dataset['train'], 'hubert-emb', 'text'), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(dataset=CusDataset(total_dataset['validation'], 'hubert-emb', 'text'), batch_size=16, shuffle=False)\n",
    "hubert_labse_model = torch.load('es_models/hubert_labse_concat_es.pt')\n",
    "hubert_labse_model = train_the_model(hubert_labse_model, train_loader, val_loader, 'es_models/hubert_labse_concat_es_v2.pt', num_epochs=400, temperature=float(np.log(0.07)), learning_rate=1e-7)\n",
    "torch.save(hubert_labse_model, 'es_models/hubert_labse_concat_es_v2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=CusDataset(total_dataset['train'], 'hubert-emb', 'text'), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(dataset=CusDataset(total_dataset['validation'], 'hubert-emb', 'text'), batch_size=16, shuffle=False)\n",
    "hubert_labse_model = HubertLabseConcat(1024, 1000, mode='image').to(device)\n",
    "hubert_labse_model = train_the_model(hubert_labse_model, train_loader, val_loader, num_epochs=400, temperature=float(np.log(0.07)))\n",
    "torch.save(hubert_labse_model, 'es_models/image_es.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=CusDataset(total_dataset['train'], 'hubert-emb', 'text'), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(dataset=CusDataset(total_dataset['validation'], 'hubert-emb', 'text'), batch_size=16, shuffle=False)\n",
    "hubert_labse_model = HubertLabseConcat(1024, 1000, mode='audio').to(device)\n",
    "hubert_labse_model = train_the_model(hubert_labse_model, train_loader, val_loader, num_epochs=400, temperature=float(np.log(0.07)))\n",
    "torch.save(hubert_labse_model, 'es_models/audio_es.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T22:47:24.057537Z",
     "iopub.status.busy": "2023-10-31T22:47:24.057136Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=CusDataset(total_dataset['train'], 'audio', 'text'), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(dataset=CusDataset(total_dataset['validation'], 'audio', 'text'), batch_size=16, shuffle=False)\n",
    "wave2vec_labse_concat = Wav2vecConcat(768, 1000).to(device)\n",
    "wave2vec_labse_concat = train_the_model(wave2vec_labse_concat, train_loader, val_loader, num_epochs=50, temperature=float(np.log(0.07)))\n",
    "torch.save(wave2vec_labse_concat, 'wave2vec_labse_concat.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave2vec_labse_concat = torch.load('wave2vec_labse_concat.pt')\n",
    "train_loader = DataLoader(dataset=CusDataset(total_dataset['train'], 'audio', 'text'), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(dataset=CusDataset(total_dataset['validation'], 'audio', 'text'), batch_size=16, shuffle=False)\n",
    "wave2vec_labse_concat = train_the_model(wave2vec_labse_concat, train_loader, val_loader, num_epochs=100)\n",
    "torch.save(wave2vec_labse_concat, 'wave2vec_labse_concat_v2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave2vec_labse_concat = torch.load('wave2vec_labse_concat_v2.pt')\n",
    "train_loader = DataLoader(dataset=CusDataset(total_dataset['train'], 'audio', 'text'), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(dataset=CusDataset(total_dataset['validation'], 'audio', 'text'), batch_size=16, shuffle=False)\n",
    "wave2vec_labse_concat = train_the_model(wave2vec_labse_concat, train_loader, val_loader, num_epochs=100, learning_rate=1e-6)\n",
    "torch.save(wave2vec_labse_concat, 'wave2vec_labse_concat_v3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-01T04:33:17.899613Z",
     "iopub.status.busy": "2023-11-01T04:33:17.898523Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "wave2vec_labse_concat = torch.load('wave2vec_labse_concat_v3.pt')\n",
    "train_loader = DataLoader(dataset=CusDataset(total_dataset['train'], 'audio', 'text'), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(dataset=CusDataset(total_dataset['validation'], 'audio', 'text'), batch_size=16, shuffle=False)\n",
    "wave2vec_labse_concat = train_the_model(wave2vec_labse_concat, train_loader, val_loader, num_epochs=50, learning_rate=5e-5)\n",
    "torch.save(wave2vec_labse_concat, 'wave2vec_labse_concat_v4.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T21:07:35.994174Z",
     "iopub.status.busy": "2023-11-14T21:07:35.993552Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=CusDataset(total_dataset['train'], 'hubert-emb', 'text'), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(dataset=CusDataset(total_dataset['validation'], 'hubert-emb', 'text'), batch_size=16, shuffle=False)\n",
    "hubert_labse_model = HubertLabseConcat(1024, 1000).to(device)\n",
    "hubert_labse_model = train_the_model(hubert_labse_model, train_loader, val_loader, num_epochs=100, temperature=float(np.log(0.07)))\n",
    "torch.save(hubert_labse_model, 'hubert_labse_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T22:04:18.447421Z",
     "iopub.status.busy": "2023-11-14T22:04:18.447035Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hubert_labse_model = torch.load('hubert_labse_model.pt')\n",
    "train_loader = DataLoader(dataset=CusDataset(total_dataset['train'], 'hubert-emb', 'text'), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(dataset=CusDataset(total_dataset['validation'], 'hubert-emb', 'text'), batch_size=16, shuffle=False)\n",
    "hubert_labse_model = train_the_model(hubert_labse_model, train_loader, val_loader, num_epochs=100)\n",
    "torch.save(hubert_labse_model, 'hubert_labse_model_v2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hubert_labse_model = torch.load('hubert_labse_model_v2.pt')\n",
    "train_loader = DataLoader(dataset=CusDataset(total_dataset['train'], 'hubert-emb', 'text'), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(dataset=CusDataset(total_dataset['validation'], 'hubert-emb', 'text'), batch_size=16, shuffle=False)\n",
    "hubert_labse_model = train_the_model(hubert_labse_model, train_loader, val_loader, num_epochs=50)\n",
    "torch.save(hubert_labse_model, 'hubert_labse_model_v3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hubert_labse_gating = HubertLabseGating(1024, 1000).to(device)\n",
    "train_loader = DataLoader(dataset=CusDataset(total_dataset['train'], 'hubert-emb', 'text'), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(dataset=CusDataset(total_dataset['validation'], 'hubert-emb', 'text'), batch_size=16, shuffle=False)\n",
    "hubert_labse_gating = train_the_model(hubert_labse_gating, train_loader, val_loader, num_epochs=150)\n",
    "torch.save(hubert_labse_gating, 'hubert_labse_gating.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hubert_labse_gating = torch.load('hubert_labse_gating.pt')\n",
    "train_loader = DataLoader(dataset=CusDataset(total_dataset['train'], 'hubert-emb', 'text'), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(dataset=CusDataset(total_dataset['validation'], 'hubert-emb', 'text'), batch_size=16, shuffle=False)\n",
    "hubert_labse_gating = train_the_model(hubert_labse_gating, train_loader, val_loader, num_epochs=100, learning_rate=1e-6)\n",
    "torch.save(hubert_labse_gating, 'hubert_labse_gating_v2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hubert_labse_gating = torch.load('hubert_labse_gating_v2.pt')\n",
    "train_loader = DataLoader(dataset=CusDataset(total_dataset['train'], 'hubert-emb', 'text'), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(dataset=CusDataset(total_dataset['validation'], 'hubert-emb', 'text'), batch_size=16, shuffle=False)\n",
    "hubert_labse_gating = train_the_model(hubert_labse_gating, train_loader, val_loader, num_epochs=50, learning_rate=5e-7)\n",
    "torch.save(hubert_labse_gating, 'hubert_labse_gating_v3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hubert_labse_model = torch.load('hubert_labse_model_v3.pt')\n",
    "train_loader = DataLoader(dataset=CusDataset(total_dataset['train'], 'hubert-emb', 'text'), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(dataset=CusDataset(total_dataset['validation'], 'hubert-emb', 'text'), batch_size=16, shuffle=False)\n",
    "hubert_labse_model = train_the_model(hubert_labse_model, train_loader, val_loader, num_epochs=50, learning_rate=2e-6)\n",
    "torch.save(hubert_labse_model, 'hubert_labse_model_v4.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soft Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T14:53:06.303629Z",
     "iopub.status.busy": "2023-12-19T14:53:06.303360Z",
     "iopub.status.idle": "2023-12-19T14:53:17.463289Z",
     "shell.execute_reply": "2023-12-19T14:53:17.462370Z",
     "shell.execute_reply.started": "2023-12-19T14:53:06.303606Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11411"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_len_data = len(total_dataset['test']['text'])\n",
    "\n",
    "number_of_candidates_per_sample = 100\n",
    "test_metadata = []\n",
    "\n",
    "for index in range(test_len_data):\n",
    "    candidate_indexes = random.sample([i for i in range(test_len_data) if i != index], number_of_candidates_per_sample - 1)\n",
    "    candidate_indexes += [index]\n",
    "    test_metadata.append(candidate_indexes)\n",
    "len(test_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T22:57:49.310597Z",
     "iopub.status.busy": "2023-12-19T22:57:49.310118Z",
     "iopub.status.idle": "2023-12-19T22:57:49.318972Z",
     "shell.execute_reply": "2023-12-19T22:57:49.317882Z",
     "shell.execute_reply.started": "2023-12-19T22:57:49.310558Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, test_dataset, metadata, audio_name, text_name):\n",
    "        self.data = test_dataset\n",
    "        self.metadata = metadata\n",
    "        self.audio_name = audio_name\n",
    "        self.text_name = text_name\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        candidate_indexes = self.metadata[index]\n",
    "        text_embedding = self.data[self.text_name][index]\n",
    "        audio_embeddings = [self.data[self.audio_name][i] for i in candidate_indexes]\n",
    "        image_embeddings = [self.data['image'][i] for i in candidate_indexes]\n",
    "        label_index = len(candidate_indexes) - 1\n",
    "        audio_embeddings = torch.stack(audio_embeddings)\n",
    "        image_embeddings = torch.stack(image_embeddings)\n",
    "\n",
    "        return text_embedding, audio_embeddings, image_embeddings, label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T22:57:49.983194Z",
     "iopub.status.busy": "2023-12-19T22:57:49.982824Z",
     "iopub.status.idle": "2023-12-19T22:57:50.003227Z",
     "shell.execute_reply": "2023-12-19T22:57:50.002298Z",
     "shell.execute_reply.started": "2023-12-19T22:57:49.983165Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model_path, threshold=0.5):\n",
    "    model = torch.load(model_path)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "\n",
    "    def compute_cosine_similarity(embedding1: torch.Tensor, embedding2: torch.Tensor) -> float:\n",
    "        similarity = cosine_similarity(embedding1.unsqueeze(0), embedding2.unsqueeze(0)).item()\n",
    "        return similarity\n",
    "\n",
    "    def cosine_similarity(embedding1, embedding2):\n",
    "        dim = 1\n",
    "        embedding1 = F.normalize(embedding1, p=2, dim=dim)\n",
    "        embedding2 = F.normalize(embedding2, p=2, dim=dim)\n",
    "\n",
    "        dot_product = torch.sum(embedding1 * embedding2, dim=dim)\n",
    "\n",
    "        magnitude1 = torch.norm(embedding1, p=2, dim=dim)\n",
    "        magnitude2 = torch.norm(embedding2, p=2, dim=dim)\n",
    "\n",
    "        cosine_sim = dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "        return cosine_sim\n",
    "    \n",
    "    def _evaluate(model, dataloader, threshold=0.5):\n",
    "        total_hits_1 = 0\n",
    "        total_mrr = 0\n",
    "        total_instances = 0\n",
    "        total_labels = []\n",
    "        total_predictions = []\n",
    "        number_of_golden_predictions = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for text_embedding, audio_candidates, image_candidates, label in tqdm(dataloader):\n",
    "                label = label[0]\n",
    "                text_embedding = text_embedding[0].to(device)\n",
    "                label = label.to(device)\n",
    "\n",
    "                audio_candidates = audio_candidates[0]\n",
    "                audio_candidates = audio_candidates.to(device)\n",
    "                \n",
    "                image_candidates = image_candidates[0]\n",
    "                image_candidates = image_candidates.to(device)\n",
    "                final_embs = model(audio_candidates, image_candidates)\n",
    "                \n",
    "                text_candidate_cosine_similarities = [compute_cosine_similarity(text_embedding, item) for item in final_embs]\n",
    "                predicted_idx = np.argmax(text_candidate_cosine_similarities)\n",
    "                \n",
    "                label_similarity = text_candidate_cosine_similarities[label.item()]\n",
    "\n",
    "                # Compute Hits@1\n",
    "                if predicted_idx == label.item():   \n",
    "                    total_hits_1 += 1\n",
    "\n",
    "                # Compute MRR\n",
    "                label_rank = sum([1 for x in text_candidate_cosine_similarities if x > text_candidate_cosine_similarities[label.item()]])\n",
    "                reciprocal_rank = 1 / (label_rank + 1)\n",
    "                total_mrr += reciprocal_rank\n",
    "\n",
    "                # Record predictions and labels\n",
    "                predictions = [0 if sim < threshold else 1 for sim in text_candidate_cosine_similarities]\n",
    "                total_labels.extend([0 if i != label.item() else 1 for i in range(len(text_candidate_cosine_similarities))])\n",
    "                total_predictions.extend(predictions)\n",
    "                if label_similarity >= threshold:\n",
    "                    number_of_golden_predictions += 1\n",
    "\n",
    "                total_instances += 1\n",
    "\n",
    "        # Compute average metrics over all instances\n",
    "        avg_hits_1 = total_hits_1 / total_instances\n",
    "        avg_mrr = total_mrr / total_instances\n",
    "        precision = precision_score(total_labels, total_predictions, average='macro')\n",
    "        recall = recall_score(total_labels, total_predictions, average='macro')\n",
    "        f1 = f1_score(total_labels, total_predictions, average='macro')\n",
    "        precision_micro = precision_score(total_labels, total_predictions, average='micro')\n",
    "        recall_micro = recall_score(total_labels, total_predictions, average='micro')\n",
    "        f1_micro = f1_score(total_labels, total_predictions, average='micro')\n",
    "        accuracy = accuracy_score(total_labels, total_predictions)\n",
    "        golden_prediction_accuracy = number_of_golden_predictions / total_instances\n",
    "\n",
    "        return {\n",
    "            'Hits@1': avg_hits_1,\n",
    "            'MRR': avg_mrr,\n",
    "            'Macro Precision': precision,\n",
    "            'Macro Recall': recall,\n",
    "            'Macro F1': f1,\n",
    "            'Micro Precision': precision_micro,\n",
    "            'Micro Recall': recall_micro,\n",
    "            'Micro F1': f1_micro,\n",
    "            'Accuracy': accuracy,\n",
    "            'Golden Accuracy': golden_prediction_accuracy,\n",
    "        }\n",
    "    \n",
    "    results = _evaluate(model, test_final_loader, threshold=threshold)\n",
    "    table = []\n",
    "    for i in range(len(results)):\n",
    "        table.append([list(results.keys())[i], list(results.values())[i]])\n",
    "    print(tabulate(table, ['Metrics', 'Values'], tablefmt=\"grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T22:57:57.059122Z",
     "iopub.status.busy": "2023-12-19T22:57:57.058269Z",
     "iopub.status.idle": "2023-12-19T23:02:32.686426Z",
     "shell.execute_reply": "2023-12-19T23:02:32.685401Z",
     "shell.execute_reply.started": "2023-12-19T22:57:57.059089Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11411/11411 [04:22<00:00, 43.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+\n",
      "| Metrics         |   Values |\n",
      "+=================+==========+\n",
      "| Hits@1          | 0.990185 |\n",
      "+-----------------+----------+\n",
      "| MRR             | 0.99355  |\n",
      "+-----------------+----------+\n",
      "| Macro Precision | 0.959362 |\n",
      "+-----------------+----------+\n",
      "| Macro Recall    | 0.979199 |\n",
      "+-----------------+----------+\n",
      "| Macro F1        | 0.969066 |\n",
      "+-----------------+----------+\n",
      "| Micro Precision | 0.998749 |\n",
      "+-----------------+----------+\n",
      "| Micro Recall    | 0.998749 |\n",
      "+-----------------+----------+\n",
      "| Micro F1        | 0.998749 |\n",
      "+-----------------+----------+\n",
      "| Accuracy        | 0.998749 |\n",
      "+-----------------+----------+\n",
      "| Golden Accuracy | 0.95925  |\n",
      "+-----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TestDataset(total_dataset['test'], test_metadata, 'hubert-emb', 'text')\n",
    "test_final_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "evaluate('es_models/hubert_labse_concat_es_v2.pt', threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T14:53:17.496695Z",
     "iopub.status.busy": "2023-12-19T14:53:17.496336Z",
     "iopub.status.idle": "2023-12-19T14:58:08.641323Z",
     "shell.execute_reply": "2023-12-19T14:58:08.640243Z",
     "shell.execute_reply.started": "2023-12-19T14:53:17.496662Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11411/11411 [04:34<00:00, 41.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+\n",
      "| Metrics         |   Values |\n",
      "+=================+==========+\n",
      "| Hits@1          | 0.990798 |\n",
      "+-----------------+----------+\n",
      "| MRR             | 0.993901 |\n",
      "+-----------------+----------+\n",
      "| Macro Precision | 0.957193 |\n",
      "+-----------------+----------+\n",
      "| Macro Recall    | 0.979393 |\n",
      "+-----------------+----------+\n",
      "| Macro F1        | 0.968024 |\n",
      "+-----------------+----------+\n",
      "| Micro Precision | 0.998703 |\n",
      "+-----------------+----------+\n",
      "| Micro Recall    | 0.998703 |\n",
      "+-----------------+----------+\n",
      "| Micro F1        | 0.998703 |\n",
      "+-----------------+----------+\n",
      "| Accuracy        | 0.998703 |\n",
      "+-----------------+----------+\n",
      "| Golden Accuracy | 0.959688 |\n",
      "+-----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TestDataset(total_dataset['test'], test_metadata, 'hubert-emb', 'text')\n",
    "test_final_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "evaluate('es_models/hubert_labse_concat_es.pt', threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T10:48:49.662456Z",
     "iopub.status.busy": "2023-11-20T10:48:49.662190Z",
     "iopub.status.idle": "2023-11-20T10:53:46.440909Z",
     "shell.execute_reply": "2023-11-20T10:53:46.439905Z",
     "shell.execute_reply.started": "2023-11-20T10:48:49.662433Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(total_dataset['test'], test_metadata, 'audio', 'text')\n",
    "test_final_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "evaluate('wave2vec_labse_concat.pt', threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(total_dataset['test'], test_metadata, 'audio', 'text')\n",
    "test_final_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "evaluate('wave2vec_labse_concat_v2.pt', threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-20T10:54:47.745985Z",
     "iopub.status.idle": "2023-11-20T10:54:47.746551Z",
     "shell.execute_reply": "2023-11-20T10:54:47.746324Z",
     "shell.execute_reply.started": "2023-11-20T10:54:47.746301Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(total_dataset['test'], test_metadata, 'audio', 'text')\n",
    "test_final_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "evaluate('wave2vec_labse_concat_v3.pt', threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-20T10:54:47.747950Z",
     "iopub.status.idle": "2023-11-20T10:54:47.748313Z",
     "shell.execute_reply": "2023-11-20T10:54:47.748169Z",
     "shell.execute_reply.started": "2023-11-20T10:54:47.748153Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(total_dataset['test'], test_metadata, 'audio', 'text')\n",
    "test_final_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "evaluate('wave2vec_labse_concat_v4.pt', threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:19:19.794391Z",
     "iopub.status.busy": "2023-12-12T10:19:19.794104Z",
     "iopub.status.idle": "2023-12-12T10:24:12.361686Z",
     "shell.execute_reply": "2023-12-12T10:24:12.360695Z",
     "shell.execute_reply.started": "2023-12-12T10:19:19.794357Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11411/11411 [04:36<00:00, 41.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+\n",
      "| Metrics         |   Values |\n",
      "+=================+==========+\n",
      "| Hits@1          | 0.989571 |\n",
      "+-----------------+----------+\n",
      "| MRR             | 0.993373 |\n",
      "+-----------------+----------+\n",
      "| Macro Precision | 0.958441 |\n",
      "+-----------------+----------+\n",
      "| Macro Recall    | 0.975774 |\n",
      "+-----------------+----------+\n",
      "| Macro F1        | 0.966943 |\n",
      "+-----------------+----------+\n",
      "| Micro Precision | 0.998666 |\n",
      "+-----------------+----------+\n",
      "| Micro Recall    | 0.998666 |\n",
      "+-----------------+----------+\n",
      "| Micro F1        | 0.998666 |\n",
      "+-----------------+----------+\n",
      "| Accuracy        | 0.998666 |\n",
      "+-----------------+----------+\n",
      "| Golden Accuracy | 0.952414 |\n",
      "+-----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TestDataset(total_dataset['test'], test_metadata, 'hubert-emb', 'text')\n",
    "test_final_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "evaluate('hubert_labse_model.pt', threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:24:12.363264Z",
     "iopub.status.busy": "2023-12-12T10:24:12.362953Z",
     "iopub.status.idle": "2023-12-12T10:29:07.727137Z",
     "shell.execute_reply": "2023-12-12T10:29:07.726127Z",
     "shell.execute_reply.started": "2023-12-12T10:24:12.363236Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11411/11411 [04:41<00:00, 40.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+\n",
      "| Metrics         |   Values |\n",
      "+=================+==========+\n",
      "| Hits@1          | 0.990535 |\n",
      "+-----------------+----------+\n",
      "| MRR             | 0.993866 |\n",
      "+-----------------+----------+\n",
      "| Macro Precision | 0.986895 |\n",
      "+-----------------+----------+\n",
      "| Macro Recall    | 0.916422 |\n",
      "+-----------------+----------+\n",
      "| Macro F1        | 0.948855 |\n",
      "+-----------------+----------+\n",
      "| Micro Precision | 0.998121 |\n",
      "+-----------------+----------+\n",
      "| Micro Recall    | 0.998121 |\n",
      "+-----------------+----------+\n",
      "| Micro F1        | 0.998121 |\n",
      "+-----------------+----------+\n",
      "| Accuracy        | 0.998121 |\n",
      "+-----------------+----------+\n",
      "| Golden Accuracy | 0.833056 |\n",
      "+-----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TestDataset(total_dataset['test'], test_metadata, 'hubert-emb', 'text')\n",
    "test_final_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "evaluate('hubert_labse_model_v2.pt', threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(total_dataset['test'], test_metadata, 'hubert-emb', 'text')\n",
    "test_final_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "evaluate('hubert_labse_model_v3.pt', threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(total_dataset['test'], test_metadata, 'hubert-emb', 'text')\n",
    "test_final_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "evaluate('hubert_labse_model_v4.pt', threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:33:57.603468Z",
     "iopub.status.busy": "2023-12-12T10:33:57.603169Z",
     "iopub.status.idle": "2023-12-12T10:38:45.832652Z",
     "shell.execute_reply": "2023-12-12T10:38:45.831720Z",
     "shell.execute_reply.started": "2023-12-12T10:33:57.603442Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11411/11411 [04:34<00:00, 41.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+\n",
      "| Metrics         |   Values |\n",
      "+=================+==========+\n",
      "| Hits@1          | 0.993603 |\n",
      "+-----------------+----------+\n",
      "| MRR             | 0.996226 |\n",
      "+-----------------+----------+\n",
      "| Macro Precision | 0.904683 |\n",
      "+-----------------+----------+\n",
      "| Macro Recall    | 0.983863 |\n",
      "+-----------------+----------+\n",
      "| Macro F1        | 0.94066  |\n",
      "+-----------------+----------+\n",
      "| Micro Precision | 0.99742  |\n",
      "+-----------------+----------+\n",
      "| Micro Recall    | 0.99742  |\n",
      "+-----------------+----------+\n",
      "| Micro F1        | 0.99742  |\n",
      "+-----------------+----------+\n",
      "| Accuracy        | 0.99742  |\n",
      "+-----------------+----------+\n",
      "| Golden Accuracy | 0.970029 |\n",
      "+-----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TestDataset(total_dataset['test'], test_metadata, 'hubert-emb', 'text')\n",
    "test_final_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "evaluate('lasp_concoat.pt', threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:38:45.834358Z",
     "iopub.status.busy": "2023-12-12T10:38:45.834043Z",
     "iopub.status.idle": "2023-12-12T10:43:34.836471Z",
     "shell.execute_reply": "2023-12-12T10:43:34.835490Z",
     "shell.execute_reply.started": "2023-12-12T10:38:45.834321Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11411/11411 [04:35<00:00, 41.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+\n",
      "| Metrics         |   Values |\n",
      "+=================+==========+\n",
      "| Hits@1          | 0.992463 |\n",
      "+-----------------+----------+\n",
      "| MRR             | 0.995251 |\n",
      "+-----------------+----------+\n",
      "| Macro Precision | 0.904098 |\n",
      "+-----------------+----------+\n",
      "| Macro Recall    | 0.586168 |\n",
      "+-----------------+----------+\n",
      "| Macro F1        | 0.640389 |\n",
      "+-----------------+----------+\n",
      "| Micro Precision | 0.991339 |\n",
      "+-----------------+----------+\n",
      "| Micro Recall    | 0.991339 |\n",
      "+-----------------+----------+\n",
      "| Micro F1        | 0.991339 |\n",
      "+-----------------+----------+\n",
      "| Accuracy        | 0.991339 |\n",
      "+-----------------+----------+\n",
      "| Golden Accuracy | 0.172728 |\n",
      "+-----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TestDataset(total_dataset['test'], test_metadata, 'hubert-emb', 'text')\n",
    "test_final_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "evaluate('lasp_gating.pt', threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T03:31:27.056236Z",
     "iopub.status.busy": "2023-12-13T03:31:27.055345Z",
     "iopub.status.idle": "2023-12-13T03:36:24.681641Z",
     "shell.execute_reply": "2023-12-13T03:36:24.680684Z",
     "shell.execute_reply.started": "2023-12-13T03:31:27.056188Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11411/11411 [04:44<00:00, 40.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+\n",
      "| Metrics         |   Values |\n",
      "+=================+==========+\n",
      "| Hits@1          | 0.991149 |\n",
      "+-----------------+----------+\n",
      "| MRR             | 0.994257 |\n",
      "+-----------------+----------+\n",
      "| Macro Precision | 0.963398 |\n",
      "+-----------------+----------+\n",
      "| Macro Recall    | 0.981521 |\n",
      "+-----------------+----------+\n",
      "| Macro F1        | 0.972282 |\n",
      "+-----------------+----------+\n",
      "| Micro Precision | 0.998881 |\n",
      "+-----------------+----------+\n",
      "| Micro Recall    | 0.998881 |\n",
      "+-----------------+----------+\n",
      "| Micro F1        | 0.998881 |\n",
      "+-----------------+----------+\n",
      "| Accuracy        | 0.998881 |\n",
      "+-----------------+----------+\n",
      "| Golden Accuracy | 0.963807 |\n",
      "+-----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TestDataset(total_dataset['test'], test_metadata, 'hubert-emb', 'text')\n",
    "test_final_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "evaluate('hubert_labse_gating.pt', threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T03:36:24.683994Z",
     "iopub.status.busy": "2023-12-13T03:36:24.683701Z",
     "iopub.status.idle": "2023-12-13T03:41:19.447418Z",
     "shell.execute_reply": "2023-12-13T03:41:19.446420Z",
     "shell.execute_reply.started": "2023-12-13T03:36:24.683968Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11411/11411 [04:41<00:00, 40.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+\n",
      "| Metrics         |   Values |\n",
      "+=================+==========+\n",
      "| Hits@1          | 0.991237 |\n",
      "+-----------------+----------+\n",
      "| MRR             | 0.994324 |\n",
      "+-----------------+----------+\n",
      "| Macro Precision | 0.962368 |\n",
      "+-----------------+----------+\n",
      "| Macro Recall    | 0.982254 |\n",
      "+-----------------+----------+\n",
      "| Macro F1        | 0.972097 |\n",
      "+-----------------+----------+\n",
      "| Micro Precision | 0.998871 |\n",
      "+-----------------+----------+\n",
      "| Micro Recall    | 0.998871 |\n",
      "+-----------------+----------+\n",
      "| Micro F1        | 0.998871 |\n",
      "+-----------------+----------+\n",
      "| Accuracy        | 0.998871 |\n",
      "+-----------------+----------+\n",
      "| Golden Accuracy | 0.965297 |\n",
      "+-----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TestDataset(total_dataset['test'], test_metadata, 'hubert-emb', 'text')\n",
    "test_final_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "evaluate('hubert_labse_gating_v2.pt', threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T03:41:19.448853Z",
     "iopub.status.busy": "2023-12-13T03:41:19.448559Z",
     "iopub.status.idle": "2023-12-13T03:46:16.333057Z",
     "shell.execute_reply": "2023-12-13T03:46:16.332075Z",
     "shell.execute_reply.started": "2023-12-13T03:41:19.448828Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11411/11411 [04:43<00:00, 40.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+\n",
      "| Metrics         |   Values |\n",
      "+=================+==========+\n",
      "| Hits@1          | 0.991412 |\n",
      "+-----------------+----------+\n",
      "| MRR             | 0.994425 |\n",
      "+-----------------+----------+\n",
      "| Macro Precision | 0.963132 |\n",
      "+-----------------+----------+\n",
      "| Macro Recall    | 0.981606 |\n",
      "+-----------------+----------+\n",
      "| Macro F1        | 0.972184 |\n",
      "+-----------------+----------+\n",
      "| Micro Precision | 0.998877 |\n",
      "+-----------------+----------+\n",
      "| Micro Recall    | 0.998877 |\n",
      "+-----------------+----------+\n",
      "| Micro F1        | 0.998877 |\n",
      "+-----------------+----------+\n",
      "| Accuracy        | 0.998877 |\n",
      "+-----------------+----------+\n",
      "| Golden Accuracy | 0.963982 |\n",
      "+-----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TestDataset(total_dataset['test'], test_metadata, 'hubert-emb', 'text')\n",
    "test_final_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "evaluate('hubert_labse_gating_v3.pt', threshold=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hard Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T11:05:31.029804Z",
     "iopub.status.busy": "2023-12-12T11:05:31.029412Z",
     "iopub.status.idle": "2023-12-12T11:05:31.588887Z",
     "shell.execute_reply": "2023-12-12T11:05:31.588059Z",
     "shell.execute_reply.started": "2023-12-12T11:05:31.029774Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 357/357 [00:00<00:00, 678.36it/s]\n"
     ]
    }
   ],
   "source": [
    "model_to_test = torch.load('hubert_labse_model_v3.pt')\n",
    "total_dataset['test']['clasp_emb'] = []\n",
    "\n",
    "test_dataloader = DataLoader(dataset=CusDataset(total_dataset['test'], 'hubert-emb', 'text'), batch_size=32, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for text_embedding, audio_candidates, image_candidates in tqdm(test_dataloader):\n",
    "        text_embedding = text_embedding.to(device)\n",
    "        audio_candidates = audio_candidates.to(device)\n",
    "        image_candidates = image_candidates.to(device)\n",
    "        final_emb = model_to_test(audio_candidates, image_candidates)\n",
    "        total_dataset['test']['clasp_emb'].extend(final_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T11:07:20.470811Z",
     "iopub.status.busy": "2023-12-12T11:07:20.469955Z",
     "iopub.status.idle": "2023-12-12T11:07:20.669065Z",
     "shell.execute_reply": "2023-12-12T11:07:20.668108Z",
     "shell.execute_reply.started": "2023-12-12T11:07:20.470775Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(total_dataset['test']['clasp_emb'])):\n",
    "    total_dataset['test']['clasp_emb'][i] = total_dataset['test']['clasp_emb'][i].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T11:07:21.849968Z",
     "iopub.status.busy": "2023-12-12T11:07:21.849642Z",
     "iopub.status.idle": "2023-12-12T11:07:21.856045Z",
     "shell.execute_reply": "2023-12-12T11:07:21.855142Z",
     "shell.execute_reply.started": "2023-12-12T11:07:21.849942Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11411"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_dataset['test']['clasp_emb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T11:07:23.194160Z",
     "iopub.status.busy": "2023-12-12T11:07:23.193806Z",
     "iopub.status.idle": "2023-12-12T11:07:23.200244Z",
     "shell.execute_reply": "2023-12-12T11:07:23.199382Z",
     "shell.execute_reply.started": "2023-12-12T11:07:23.194131Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_dataset['test']['clasp_emb'][0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T11:07:24.045959Z",
     "iopub.status.busy": "2023-12-12T11:07:24.045600Z",
     "iopub.status.idle": "2023-12-12T11:07:24.052127Z",
     "shell.execute_reply": "2023-12-12T11:07:24.051311Z",
     "shell.execute_reply.started": "2023-12-12T11:07:24.045927Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_dataset['test']['text'][0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T11:07:40.649453Z",
     "iopub.status.busy": "2023-12-12T11:07:40.649100Z",
     "iopub.status.idle": "2023-12-12T11:07:42.249540Z",
     "shell.execute_reply": "2023-12-12T11:07:42.248493Z",
     "shell.execute_reply.started": "2023-12-12T11:07:40.649424Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "similarity_dataset = {}\n",
    "similarity_dataset['clasp_emb'] = total_dataset['test']['clasp_emb']\n",
    "similarity_dataset['text'] = total_dataset['test']['text']\n",
    "\n",
    "with open('similarity_dataset.pkl', 'wb') as f:\n",
    "    pickle.dump(similarity_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T23:58:45.381151Z",
     "iopub.status.busy": "2023-12-19T23:58:45.380867Z",
     "iopub.status.idle": "2023-12-19T23:58:45.390942Z",
     "shell.execute_reply": "2023-12-19T23:58:45.390137Z",
     "shell.execute_reply.started": "2023-12-19T23:58:45.381127Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(embedding1, embedding2):\n",
    "    dim = 1\n",
    "    embedding1 = F.normalize(embedding1, p=2, dim=dim)\n",
    "    embedding2 = F.normalize(embedding2, p=2, dim=dim)\n",
    "\n",
    "    dot_product = torch.sum(embedding1 * embedding2, dim=dim)\n",
    "\n",
    "    magnitude1 = torch.norm(embedding1, p=2, dim=dim)\n",
    "    magnitude2 = torch.norm(embedding2, p=2, dim=dim)\n",
    "\n",
    "    cosine_sim = dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "    return cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T11:13:40.809654Z",
     "iopub.status.busy": "2023-12-12T11:13:40.809274Z",
     "iopub.status.idle": "2023-12-12T14:26:20.352252Z",
     "shell.execute_reply": "2023-12-12T14:26:20.351315Z",
     "shell.execute_reply.started": "2023-12-12T11:13:40.809622Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11411/11411 [3:12:39<00:00,  1.01s/it] \n"
     ]
    }
   ],
   "source": [
    "# build similarity matrix between text and clasp_emb, similarity_matrix[i][j] shows cosine similarity betewen clasp_emb[i] and text[j]\n",
    "similarity_matrix = []\n",
    "for i in tqdm(range(len(similarity_dataset['clasp_emb']))):\n",
    "    similarity_matrix.append([])\n",
    "    for j in range(len(similarity_dataset['text'])):\n",
    "        similarity_matrix[i].append(cosine_similarity(similarity_dataset['clasp_emb'][i].unsqueeze(0), similarity_dataset['text'][j].unsqueeze(0)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T14:27:48.247022Z",
     "iopub.status.busy": "2023-12-12T14:27:48.246373Z",
     "iopub.status.idle": "2023-12-12T14:27:53.399649Z",
     "shell.execute_reply": "2023-12-12T14:27:53.398667Z",
     "shell.execute_reply.started": "2023-12-12T14:27:48.246990Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open('similarity_matrix.pkl', 'wb') as f:\n",
    "    pickle.dump(similarity_matrix, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T15:08:16.280801Z",
     "iopub.status.busy": "2023-12-19T15:08:16.280446Z",
     "iopub.status.idle": "2023-12-19T15:08:16.294986Z",
     "shell.execute_reply": "2023-12-19T15:08:16.294070Z",
     "shell.execute_reply.started": "2023-12-19T15:08:16.280775Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_(similarity_matrix, threshold=0.5):\n",
    "\n",
    "    def _evaluate(similarity_matrix, threshold=0.5):\n",
    "        total_hits_1 = 0\n",
    "        total_mrr = 0\n",
    "        total_instances = 0\n",
    "        total_labels = []\n",
    "        total_predictions = []\n",
    "        number_of_golden_predictions = 0\n",
    "\n",
    "        for i in tqdm(range(len(similarity_matrix))):\n",
    "            predicted_idx = np.argmax(similarity_matrix[i])\n",
    "            label_similarity = similarity_matrix[i][i]\n",
    "\n",
    "            # Compute Hits@1\n",
    "            if predicted_idx == i:   \n",
    "                total_hits_1 += 1\n",
    "\n",
    "            # Compute MRR\n",
    "            label_rank = sum([1 for x in similarity_matrix[i] if x > similarity_matrix[i][i]])\n",
    "            reciprocal_rank = 1 / (label_rank + 1)\n",
    "            total_mrr += reciprocal_rank\n",
    "\n",
    "            # Record predictions and labels\n",
    "            predictions = [0 if sim < threshold else 1 for sim in similarity_matrix[i]]\n",
    "            total_labels.extend([0 if k != i else 1 for k in range(len(similarity_matrix[i]))])\n",
    "            total_predictions.extend(predictions)\n",
    "            if label_similarity >= threshold:\n",
    "                number_of_golden_predictions += 1\n",
    "\n",
    "            total_instances += 1\n",
    "\n",
    "\n",
    "        # Compute average metrics over all instances\n",
    "        avg_hits_1 = total_hits_1 / total_instances\n",
    "        avg_mrr = total_mrr / total_instances\n",
    "        precision = precision_score(total_labels, total_predictions, average='macro')\n",
    "        recall = recall_score(total_labels, total_predictions, average='macro')\n",
    "        f1 = f1_score(total_labels, total_predictions, average='macro')\n",
    "        precision_micro = precision_score(total_labels, total_predictions, average='micro')\n",
    "        recall_micro = recall_score(total_labels, total_predictions, average='micro')\n",
    "        f1_micro = f1_score(total_labels, total_predictions, average='micro')\n",
    "        accuracy = accuracy_score(total_labels, total_predictions)\n",
    "        golden_prediction_accuracy = number_of_golden_predictions / total_instances\n",
    "\n",
    "        return {\n",
    "            'Hits@1': avg_hits_1,\n",
    "            'MRR': avg_mrr,\n",
    "            'Macro Precision': precision,\n",
    "            'Macro Recall': recall,\n",
    "            'Macro F1': f1,\n",
    "            'Micro Precision': precision_micro,\n",
    "            'Micro Recall': recall_micro,\n",
    "            'Micro F1': f1_micro,\n",
    "            'Accuracy': accuracy,\n",
    "            'Golden Accuracy': golden_prediction_accuracy,\n",
    "        }\n",
    "    \n",
    "    results = _evaluate(similarity_matrix, threshold=threshold)\n",
    "    table = []\n",
    "    for i in range(len(results)):\n",
    "        table.append([list(results.keys())[i], list(results.values())[i]])\n",
    "    print(tabulate(table, ['Metrics', 'Values'], tablefmt=\"grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T14:28:32.398648Z",
     "iopub.status.busy": "2023-12-12T14:28:32.398274Z",
     "iopub.status.idle": "2023-12-12T14:56:56.599742Z",
     "shell.execute_reply": "2023-12-12T14:56:56.598757Z",
     "shell.execute_reply.started": "2023-12-12T14:28:32.398618Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11411/11411 [00:49<00:00, 229.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+\n",
      "| Metrics         |   Values |\n",
      "+=================+==========+\n",
      "| Hits@1          | 0.910525 |\n",
      "+-----------------+----------+\n",
      "| MRR             | 0.955484 |\n",
      "+-----------------+----------+\n",
      "| Macro Precision | 0.634033 |\n",
      "+-----------------+----------+\n",
      "| Macro Recall    | 0.918312 |\n",
      "+-----------------+----------+\n",
      "| Macro F1        | 0.702983 |\n",
      "+-----------------+----------+\n",
      "| Micro Precision | 0.999785 |\n",
      "+-----------------+----------+\n",
      "| Micro Recall    | 0.999785 |\n",
      "+-----------------+----------+\n",
      "| Micro F1        | 0.999785 |\n",
      "+-----------------+----------+\n",
      "| Accuracy        | 0.999785 |\n",
      "+-----------------+----------+\n",
      "| Golden Accuracy | 0.836824 |\n",
      "+-----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "evaluate(similarity_matrix, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T15:00:20.075601Z",
     "iopub.status.busy": "2023-12-12T15:00:20.074777Z",
     "iopub.status.idle": "2023-12-12T15:00:21.302667Z",
     "shell.execute_reply": "2023-12-12T15:00:21.301757Z",
     "shell.execute_reply.started": "2023-12-12T15:00:20.075565Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 357/357 [00:00<00:00, 359.08it/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'lasp_concat'\n",
    "model_to_test = torch.load(f'lasp_concoat.pt')\n",
    "total_dataset['test'][f'{model_name}_emb'] = []\n",
    "\n",
    "test_dataloader = DataLoader(dataset=CusDataset(total_dataset['test'], 'hubert-emb', 'text'), batch_size=32, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for text_embedding, audio_candidates, image_candidates in tqdm(test_dataloader):\n",
    "        text_embedding = text_embedding.to(device)\n",
    "        audio_candidates = audio_candidates.to(device)\n",
    "        image_candidates = image_candidates.to(device)\n",
    "        final_emb = model_to_test(audio_candidates, image_candidates)\n",
    "        total_dataset['test'][f'{model_name}_emb'].extend(final_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T15:01:46.204798Z",
     "iopub.status.busy": "2023-12-12T15:01:46.203681Z",
     "iopub.status.idle": "2023-12-12T15:01:46.411012Z",
     "shell.execute_reply": "2023-12-12T15:01:46.410283Z",
     "shell.execute_reply.started": "2023-12-12T15:01:46.204761Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(total_dataset['test'][f'{model_name}_emb'])):\n",
    "    total_dataset['test'][f'{model_name}_emb'][i] = total_dataset['test'][f'{model_name}_emb'][i].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T15:04:02.583190Z",
     "iopub.status.busy": "2023-12-12T15:04:02.582802Z",
     "iopub.status.idle": "2023-12-12T18:17:37.522835Z",
     "shell.execute_reply": "2023-12-12T18:17:37.521956Z",
     "shell.execute_reply.started": "2023-12-12T15:04:02.583161Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11411/11411 [3:13:28<00:00,  1.02s/it] \n"
     ]
    }
   ],
   "source": [
    "similarity_dataset = {}\n",
    "similarity_dataset[f'{model_name}_emb'] = total_dataset['test'][f'{model_name}_emb']\n",
    "similarity_dataset['text'] = total_dataset['test']['text']\n",
    "\n",
    "similarity_matrix = []\n",
    "for i in tqdm(range(len(similarity_dataset[f'{model_name}_emb']))):\n",
    "    similarity_matrix.append([])\n",
    "    for j in range(len(similarity_dataset['text'])):\n",
    "        similarity_matrix[i].append(cosine_similarity(similarity_dataset[f'{model_name}_emb'][i].unsqueeze(0), similarity_dataset['text'][j].unsqueeze(0)).item())\n",
    "        \n",
    "with open(f'similarity_matrix_{model_name}.pkl', 'wb') as f:\n",
    "    pickle.dump(similarity_matrix, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T18:21:03.115862Z",
     "iopub.status.busy": "2023-12-12T18:21:03.115474Z",
     "iopub.status.idle": "2023-12-12T18:49:23.788502Z",
     "shell.execute_reply": "2023-12-12T18:49:23.787508Z",
     "shell.execute_reply.started": "2023-12-12T18:21:03.115834Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11411/11411 [00:49<00:00, 230.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+\n",
      "| Metrics         |   Values |\n",
      "+=================+==========+\n",
      "| Hits@1          | 0.853562 |\n",
      "+-----------------+----------+\n",
      "| MRR             | 0.911378 |\n",
      "+-----------------+----------+\n",
      "| Macro Precision | 0.517825 |\n",
      "+-----------------+----------+\n",
      "| Macro Recall    | 0.983865 |\n",
      "+-----------------+----------+\n",
      "| Macro F1        | 0.533813 |\n",
      "+-----------------+----------+\n",
      "| Micro Precision | 0.997698 |\n",
      "+-----------------+----------+\n",
      "| Micro Recall    | 0.997698 |\n",
      "+-----------------+----------+\n",
      "| Micro F1        | 0.997698 |\n",
      "+-----------------+----------+\n",
      "| Accuracy        | 0.997698 |\n",
      "+-----------------+----------+\n",
      "| Golden Accuracy | 0.970029 |\n",
      "+-----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "evaluate(similarity_matrix, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T18:56:59.788569Z",
     "iopub.status.busy": "2023-12-12T18:56:59.787798Z",
     "iopub.status.idle": "2023-12-12T18:56:59.794303Z",
     "shell.execute_reply": "2023-12-12T18:56:59.793507Z",
     "shell.execute_reply.started": "2023-12-12T18:56:59.788538Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['audio', 'text', 'image', 'xlmr-emb', 'hubert-emb', 'pure-text', 'id', 'source', 'audio_path', 'clasp_emb', 'lasp_concat_emb'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_dataset['test'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 357/357 [00:00<00:00, 563.85it/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'hubert_labse_gating_v3'\n",
    "model_to_test = torch.load(f'{model_name}.pt')\n",
    "total_dataset['test'][f'{model_name}_emb'] = []\n",
    "\n",
    "test_dataloader = DataLoader(dataset=CusDataset(total_dataset['test'], 'hubert-emb', 'text'), batch_size=32, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for text_embedding, audio_candidates, image_candidates in tqdm(test_dataloader):\n",
    "        text_embedding = text_embedding.to(device)\n",
    "        audio_candidates = audio_candidates.to(device)\n",
    "        image_candidates = image_candidates.to(device)\n",
    "        final_emb = model_to_test(audio_candidates, image_candidates)\n",
    "        total_dataset['test'][f'{model_name}_emb'].extend(final_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(total_dataset['test'][f'{model_name}_emb'])):\n",
    "    total_dataset['test'][f'{model_name}_emb'][i] = total_dataset['test'][f'{model_name}_emb'][i].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11411/11411 [1:10:33<00:00,  2.70it/s]\n"
     ]
    }
   ],
   "source": [
    "similarity_dataset = {}\n",
    "similarity_dataset[f'{model_name}_emb'] = total_dataset['test'][f'{model_name}_emb']\n",
    "similarity_dataset['text'] = total_dataset['test']['text']\n",
    "\n",
    "similarity_matrix = []\n",
    "for i in tqdm(range(len(similarity_dataset[f'{model_name}_emb']))):\n",
    "    similarity_matrix.append([])\n",
    "    for j in range(len(similarity_dataset['text'])):\n",
    "        similarity_matrix[i].append(cosine_similarity(similarity_dataset[f'{model_name}_emb'][i].unsqueeze(0), similarity_dataset['text'][j].unsqueeze(0)).item())\n",
    "        \n",
    "with open(f'similarity_matrix_{model_name}.pkl', 'wb') as f:\n",
    "    pickle.dump(similarity_matrix, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11411/11411 [00:51<00:00, 222.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+\n",
      "| Metrics         |   Values |\n",
      "+=================+==========+\n",
      "| Hits@1          | 0.908159 |\n",
      "+-----------------+----------+\n",
      "| MRR             | 0.954224 |\n",
      "+-----------------+----------+\n",
      "| Macro Precision | 0.635481 |\n",
      "+-----------------+----------+\n",
      "| Macro Recall    | 0.912093 |\n",
      "+-----------------+----------+\n",
      "| Macro F1        | 0.703889 |\n",
      "+-----------------+----------+\n",
      "| Micro Precision | 0.99979  |\n",
      "+-----------------+----------+\n",
      "| Micro Recall    | 0.99979  |\n",
      "+-----------------+----------+\n",
      "| Micro F1        | 0.99979  |\n",
      "+-----------------+----------+\n",
      "| Accuracy        | 0.99979  |\n",
      "+-----------------+----------+\n",
      "| Golden Accuracy | 0.82438  |\n",
      "+-----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "evaluate(similarity_matrix, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_matrix(similarity_matrix, threshold=0.5):\n",
    "\n",
    "    def _evaluate(similarity_matrix, threshold=0.5):\n",
    "        total_hits_1 = 0\n",
    "        total_mrr = 0\n",
    "        total_instances = 0\n",
    "        total_labels = []\n",
    "        total_predictions = []\n",
    "        number_of_golden_predictions = 0\n",
    "\n",
    "        for i in tqdm(range(len(similarity_matrix))):\n",
    "            predicted_idx = np.argmax(similarity_matrix[i])\n",
    "            label_similarity = similarity_matrix[i][i]\n",
    "\n",
    "            # Compute Hits@1\n",
    "            if predicted_idx == i:   \n",
    "                total_hits_1 += 1\n",
    "\n",
    "            # Compute MRR\n",
    "            label_rank = sum([1 for x in similarity_matrix[i] if x > similarity_matrix[i][i]])\n",
    "            reciprocal_rank = 1 / (label_rank + 1)\n",
    "            total_mrr += reciprocal_rank\n",
    "\n",
    "            # Record predictions and labels\n",
    "            predictions = [0 if sim < threshold else 1 for sim in similarity_matrix[i]]\n",
    "            total_labels.extend([0 if k != i else 1 for k in range(len(similarity_matrix[i]))])\n",
    "            total_predictions.extend(predictions)\n",
    "            if label_similarity >= threshold:\n",
    "                number_of_golden_predictions += 1\n",
    "\n",
    "            total_instances += 1\n",
    "\n",
    "\n",
    "        # Compute average metrics over all instances\n",
    "        avg_hits_1 = total_hits_1 / total_instances\n",
    "        avg_mrr = total_mrr / total_instances\n",
    "        precision = precision_score(total_labels, total_predictions, average='macro')\n",
    "        recall = recall_score(total_labels, total_predictions, average='macro')\n",
    "        f1 = f1_score(total_labels, total_predictions, average='macro')\n",
    "        precision_micro = precision_score(total_labels, total_predictions, average='micro')\n",
    "        recall_micro = recall_score(total_labels, total_predictions, average='micro')\n",
    "        f1_micro = f1_score(total_labels, total_predictions, average='micro')\n",
    "        accuracy = accuracy_score(total_labels, total_predictions)\n",
    "        golden_prediction_accuracy = number_of_golden_predictions / total_instances\n",
    "\n",
    "        return {\n",
    "            'Hits@1': avg_hits_1,\n",
    "            'MRR': avg_mrr,\n",
    "            'Macro Precision': precision,\n",
    "            'Macro Recall': recall,\n",
    "            'Macro F1': f1,\n",
    "            'Micro Precision': precision_micro,\n",
    "            'Micro Recall': recall_micro,\n",
    "            'Micro F1': f1_micro,\n",
    "            'Accuracy': accuracy,\n",
    "            'Golden Accuracy': golden_prediction_accuracy,\n",
    "        }\n",
    "    \n",
    "    results = _evaluate(similarity_matrix, threshold=threshold)\n",
    "    table = []\n",
    "    for i in range(len(results)):\n",
    "        table.append([list(results.keys())[i], list(results.values())[i]])\n",
    "    print(tabulate(table, ['Metrics', 'Values'], tablefmt=\"grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_evaluate(model_name, directory=''):\n",
    "    if directory == '':\n",
    "        model_to_test = torch.load(f'{model_name}.pt')\n",
    "    else:\n",
    "        model_to_test = torch.load(f'{directory}/{model_name}.pt')\n",
    "    total_dataset['test'][f'{model_name}_emb'] = []\n",
    "\n",
    "    test_dataloader = DataLoader(dataset=CusDataset(total_dataset['test'], 'hubert-emb', 'text'), batch_size=32, shuffle=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for text_embedding, audio_candidates, image_candidates in tqdm(test_dataloader):\n",
    "            text_embedding = text_embedding.to(device)\n",
    "            audio_candidates = audio_candidates.to(device)\n",
    "            image_candidates = image_candidates.to(device)\n",
    "            final_emb = model_to_test(audio_candidates, image_candidates)\n",
    "            total_dataset['test'][f'{model_name}_emb'].extend(final_emb)\n",
    "\n",
    "    for i in range(len(total_dataset['test'][f'{model_name}_emb'])):\n",
    "        total_dataset['test'][f'{model_name}_emb'][i] = total_dataset['test'][f'{model_name}_emb'][i].cpu()\n",
    "\n",
    "    similarity_dataset = {}\n",
    "    similarity_dataset[f'{model_name}_emb'] = total_dataset['test'][f'{model_name}_emb']\n",
    "    similarity_dataset['text'] = total_dataset['test']['text']\n",
    "\n",
    "    similarity_matrix = []\n",
    "    for i in tqdm(range(len(similarity_dataset[f'{model_name}_emb']))):\n",
    "        similarity_matrix.append([])\n",
    "        for j in range(len(similarity_dataset['text'])):\n",
    "            similarity_matrix[i].append(cosine_similarity(similarity_dataset[f'{model_name}_emb'][i].unsqueeze(0), similarity_dataset['text'][j].unsqueeze(0)).item())\n",
    "\n",
    "    with open(f'similarity_matrix_{model_name}.pkl', 'wb') as f:\n",
    "        pickle.dump(similarity_matrix, f)\n",
    "    \n",
    "    with open('model_name.txt', 'w') as f:\n",
    "        f.write(f'{model_name}')\n",
    "    \n",
    "    evaluate_matrix(similarity_matrix, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 357/357 [00:02<00:00, 167.71it/s]\n",
      "100%|██████████| 11411/11411 [3:09:34<00:00,  1.00it/s] \n",
      "100%|██████████| 11411/11411 [00:50<00:00, 226.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+\n",
      "| Metrics         |   Values |\n",
      "+=================+==========+\n",
      "| Hits@1          | 0.911489 |\n",
      "+-----------------+----------+\n",
      "| MRR             | 0.9567   |\n",
      "+-----------------+----------+\n",
      "| Macro Precision | 0.63786  |\n",
      "+-----------------+----------+\n",
      "| Macro Recall    | 0.92423  |\n",
      "+-----------------+----------+\n",
      "| Macro F1        | 0.708063 |\n",
      "+-----------------+----------+\n",
      "| Micro Precision | 0.999791 |\n",
      "+-----------------+----------+\n",
      "| Micro Recall    | 0.999791 |\n",
      "+-----------------+----------+\n",
      "| Micro F1        | 0.999791 |\n",
      "+-----------------+----------+\n",
      "| Accuracy        | 0.999791 |\n",
      "+-----------------+----------+\n",
      "| Golden Accuracy | 0.848655 |\n",
      "+-----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "hard_evaluate('hubert_labse_model_es')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hubert ASR Hard Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T19:01:31.820061Z",
     "iopub.status.busy": "2023-12-12T19:01:31.819345Z",
     "iopub.status.idle": "2023-12-12T19:01:46.701173Z",
     "shell.execute_reply": "2023-12-12T19:01:46.700212Z",
     "shell.execute_reply.started": "2023-12-12T19:01:31.820028Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1UChSPa_Uv6levN9pWN9jkNkBgkJWi6nL\n",
      "From (redirected): https://drive.google.com/uc?id=1UChSPa_Uv6levN9pWN9jkNkBgkJWi6nL&confirm=t&uuid=abbf98d0-cc33-44f7-907a-6ed13364a030\n",
      "To: /kaggle/working/total_dataset_hubert_asr_v2.pkl\n",
      "100%|██████████| 1.50G/1.50G [00:14<00:00, 106MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'total_dataset_hubert_asr_v2.pkl'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://drive.google.com/file/d/1UChSPa_Uv6levN9pWN9jkNkBgkJWi6nL/view?usp=sharing\"\n",
    "output = \"total_dataset_hubert_asr_v2.pkl\"\n",
    "gdown.download(url, output, quiet=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T22:32:15.524081Z",
     "iopub.status.busy": "2023-12-12T22:32:15.523620Z",
     "iopub.status.idle": "2023-12-12T22:32:22.203345Z",
     "shell.execute_reply": "2023-12-12T22:32:22.202338Z",
     "shell.execute_reply.started": "2023-12-12T22:32:15.524039Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open('total_dataset_hubert_asr_v2.pkl', 'rb') as f:\n",
    "    total_dataset_test_asr = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T22:32:22.209398Z",
     "iopub.status.busy": "2023-12-12T22:32:22.209085Z",
     "iopub.status.idle": "2023-12-12T22:32:22.215274Z",
     "shell.execute_reply": "2023-12-12T22:32:22.214359Z",
     "shell.execute_reply.started": "2023-12-12T22:32:22.209372Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['audio', 'image', 'text', 'pure-text', 'audio_path', 'id', 'source', 'asr-text', 'asr-text-embedding', 'hubert-emb', 'hubert-emb-768', 'hubert-asr-text'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_dataset_test_asr.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T22:32:22.216551Z",
     "iopub.status.busy": "2023-12-12T22:32:22.216305Z",
     "iopub.status.idle": "2023-12-12T22:32:22.228078Z",
     "shell.execute_reply": "2023-12-12T22:32:22.227029Z",
     "shell.execute_reply.started": "2023-12-12T22:32:22.216530Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this area has to provide some insight into these farming adaptations'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_dataset_test_asr['hubert-asr-text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T22:32:22.230456Z",
     "iopub.status.busy": "2023-12-12T22:32:22.229936Z",
     "iopub.status.idle": "2023-12-12T22:32:22.239347Z",
     "shell.execute_reply": "2023-12-12T22:32:22.238516Z",
     "shell.execute_reply.started": "2023-12-12T22:32:22.230431Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this area helps to provide some insight into these farming adaptations'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_dataset_test_asr['pure-text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T22:32:22.240725Z",
     "iopub.status.busy": "2023-12-12T22:32:22.240395Z",
     "iopub.status.idle": "2023-12-12T22:32:22.250662Z",
     "shell.execute_reply": "2023-12-12T22:32:22.249816Z",
     "shell.execute_reply.started": "2023-12-12T22:32:22.240693Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11411"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_dataset_test_asr['hubert-asr-text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T22:32:22.251910Z",
     "iopub.status.busy": "2023-12-12T22:32:22.251613Z",
     "iopub.status.idle": "2023-12-12T22:32:22.263149Z",
     "shell.execute_reply": "2023-12-12T22:32:22.262217Z",
     "shell.execute_reply.started": "2023-12-12T22:32:22.251886Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11411"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_dataset_test_asr['pure-text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:08:51.293060Z",
     "iopub.status.busy": "2024-01-04T20:08:51.292785Z",
     "iopub.status.idle": "2024-01-04T20:09:40.758590Z",
     "shell.execute_reply": "2024-01-04T20:09:40.757767Z",
     "shell.execute_reply.started": "2024-01-04T20:08:51.293036Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "text_model = SentenceTransformer('sentence-transformers/LaBSE').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T22:32:54.123185Z",
     "iopub.status.busy": "2023-12-12T22:32:54.122772Z",
     "iopub.status.idle": "2023-12-12T22:33:06.199464Z",
     "shell.execute_reply": "2023-12-12T22:33:06.198637Z",
     "shell.execute_reply.started": "2023-12-12T22:32:54.123148Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cef4fc3f3bfe4ca2a8673ff87bc4183c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = text_model.encode(total_dataset_test_asr['hubert-asr-text'])\n",
    "total_dataset_test_asr['hubert-asr-emb'] = [torch.from_numpy(emb) for emb in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T22:33:06.201058Z",
     "iopub.status.busy": "2023-12-12T22:33:06.200700Z",
     "iopub.status.idle": "2023-12-12T23:41:10.738982Z",
     "shell.execute_reply": "2023-12-12T23:41:10.738118Z",
     "shell.execute_reply.started": "2023-12-12T22:33:06.201025Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11411/11411 [1:07:59<00:00,  2.80it/s]\n"
     ]
    }
   ],
   "source": [
    "similarity_dataset = {}\n",
    "similarity_dataset['hubert-asr-emb'] = total_dataset_test_asr['hubert-asr-emb']\n",
    "similarity_dataset['text'] = total_dataset_test_asr['text']\n",
    "\n",
    "similarity_matrix = []\n",
    "for i in tqdm(range(len(similarity_dataset['hubert-asr-emb']))):\n",
    "    similarity_matrix.append([])\n",
    "    for j in range(len(similarity_dataset['text'])):\n",
    "        similarity_matrix[i].append(cosine_similarity(similarity_dataset['hubert-asr-emb'][i].unsqueeze(0), similarity_dataset['text'][j].unsqueeze(0)).item())\n",
    "        \n",
    "with open(f'similarity_matrix_hubert_asr.pkl', 'wb') as f:\n",
    "    pickle.dump(similarity_matrix, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T23:41:29.695809Z",
     "iopub.status.busy": "2023-12-12T23:41:29.694942Z",
     "iopub.status.idle": "2023-12-13T00:09:45.240934Z",
     "shell.execute_reply": "2023-12-13T00:09:45.239985Z",
     "shell.execute_reply.started": "2023-12-12T23:41:29.695772Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11411/11411 [00:48<00:00, 235.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+\n",
      "| Metrics         |   Values |\n",
      "+=================+==========+\n",
      "| Hits@1          | 0.926562 |\n",
      "+-----------------+----------+\n",
      "| MRR             | 0.963825 |\n",
      "+-----------------+----------+\n",
      "| Macro Precision | 0.611018 |\n",
      "+-----------------+----------+\n",
      "| Macro Recall    | 0.986004 |\n",
      "+-----------------+----------+\n",
      "| Macro F1        | 0.680684 |\n",
      "+-----------------+----------+\n",
      "| Micro Precision | 0.999699 |\n",
      "+-----------------+----------+\n",
      "| Micro Recall    | 0.999699 |\n",
      "+-----------------+----------+\n",
      "| Micro F1        | 0.999699 |\n",
      "+-----------------+----------+\n",
      "| Accuracy        | 0.999699 |\n",
      "+-----------------+----------+\n",
      "| Golden Accuracy | 0.972307 |\n",
      "+-----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "evaluate(similarity_matrix, threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wav2vec2 ASR Hard Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:11:02.701622Z",
     "iopub.status.busy": "2024-01-04T20:11:02.701243Z",
     "iopub.status.idle": "2024-01-04T20:11:12.497913Z",
     "shell.execute_reply": "2024-01-04T20:11:12.495447Z",
     "shell.execute_reply.started": "2024-01-04T20:11:02.701593Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open('total_dataset_hubert_asr_v2.pkl', 'rb') as f:\n",
    "    total_dataset_test_asr = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:11:12.505306Z",
     "iopub.status.busy": "2024-01-04T20:11:12.504972Z",
     "iopub.status.idle": "2024-01-04T20:11:12.511725Z",
     "shell.execute_reply": "2024-01-04T20:11:12.510611Z",
     "shell.execute_reply.started": "2024-01-04T20:11:12.505280Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['audio', 'image', 'text', 'pure-text', 'audio_path', 'id', 'source', 'asr-text', 'asr-text-embedding', 'hubert-emb', 'hubert-emb-768', 'hubert-asr-text'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_dataset_test_asr.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:12:37.189917Z",
     "iopub.status.busy": "2024-01-04T20:12:37.189228Z",
     "iopub.status.idle": "2024-01-04T20:12:37.196005Z",
     "shell.execute_reply": "2024-01-04T20:12:37.195140Z",
     "shell.execute_reply.started": "2024-01-04T20:12:37.189885Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11411"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_dataset_test_asr['asr-text-embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:11:55.273833Z",
     "iopub.status.busy": "2024-01-04T20:11:55.273004Z",
     "iopub.status.idle": "2024-01-04T20:11:55.280914Z",
     "shell.execute_reply": "2024-01-04T20:11:55.279961Z",
     "shell.execute_reply.started": "2024-01-04T20:11:55.273790Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_dataset_test_asr['asr-text-embedding'][0] != total_dataset_test_asr['asr-text-embedding'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:13:23.566289Z",
     "iopub.status.busy": "2024-01-04T20:13:23.565893Z",
     "iopub.status.idle": "2024-01-04T20:13:35.721044Z",
     "shell.execute_reply": "2024-01-04T20:13:35.720259Z",
     "shell.execute_reply.started": "2024-01-04T20:13:23.566259Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c3a905f1a94aad9160693ab8437218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = text_model.encode(total_dataset_test_asr['asr-text'])\n",
    "total_dataset_test_asr['asr-text-embedding'] = [torch.from_numpy(emb) for emb in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T13:03:13.490801Z",
     "iopub.status.busy": "2024-10-27T13:03:13.489846Z",
     "iopub.status.idle": "2024-10-27T13:03:13.497030Z",
     "shell.execute_reply": "2024-10-27T13:03:13.496070Z",
     "shell.execute_reply.started": "2024-10-27T13:03:13.490762Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(embedding1, embedding2):\n",
    "    dim = 1\n",
    "    embedding1 = F.normalize(embedding1, p=2, dim=dim)\n",
    "    embedding2 = F.normalize(embedding2, p=2, dim=dim)\n",
    "\n",
    "    dot_product = torch.sum(embedding1 * embedding2, dim=dim)\n",
    "\n",
    "    magnitude1 = torch.norm(embedding1, p=2, dim=dim)\n",
    "    magnitude2 = torch.norm(embedding2, p=2, dim=dim)\n",
    "\n",
    "    cosine_sim = dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "    return cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:16:28.420901Z",
     "iopub.status.busy": "2024-01-04T20:16:28.420507Z",
     "iopub.status.idle": "2024-01-04T23:35:37.322850Z",
     "shell.execute_reply": "2024-01-04T23:35:37.321680Z",
     "shell.execute_reply.started": "2024-01-04T20:16:28.420870Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11411/11411 [3:19:03<00:00,  1.05s/it] \n"
     ]
    }
   ],
   "source": [
    "similarity_dataset = {}\n",
    "similarity_dataset['asr-text-embedding'] = total_dataset_test_asr['asr-text-embedding']\n",
    "similarity_dataset['text'] = total_dataset_test_asr['text']\n",
    "\n",
    "similarity_matrix = []\n",
    "for i in tqdm(range(len(similarity_dataset['asr-text-embedding']))):\n",
    "    similarity_matrix.append([])\n",
    "    for j in range(len(similarity_dataset['text'])):\n",
    "        similarity_matrix[i].append(cosine_similarity(similarity_dataset['asr-text-embedding'][i].unsqueeze(0), similarity_dataset['text'][j].unsqueeze(0)).item())\n",
    "        \n",
    "with open(f'similarity_matrix_wav2vec2_asr.pkl', 'wb') as f:\n",
    "    pickle.dump(similarity_matrix, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T23:56:48.329084Z",
     "iopub.status.busy": "2024-01-04T23:56:48.328281Z",
     "iopub.status.idle": "2024-01-04T23:56:48.344506Z",
     "shell.execute_reply": "2024-01-04T23:56:48.343420Z",
     "shell.execute_reply.started": "2024-01-04T23:56:48.329049Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(similarity_matrix, threshold=0.5):\n",
    "\n",
    "    def _evaluate(similarity_matrix, threshold=0.5):\n",
    "        total_hits_1 = 0\n",
    "        total_mrr = 0\n",
    "        total_instances = 0\n",
    "        total_labels = []\n",
    "        total_predictions = []\n",
    "        number_of_golden_predictions = 0\n",
    "\n",
    "        for i in tqdm(range(len(similarity_matrix))):\n",
    "            predicted_idx = np.argmax(similarity_matrix[i])\n",
    "            label_similarity = similarity_matrix[i][i]\n",
    "\n",
    "            # Compute Hits@1\n",
    "            if predicted_idx == i:   \n",
    "                total_hits_1 += 1\n",
    "\n",
    "            # Compute MRR\n",
    "            label_rank = sum([1 for x in similarity_matrix[i] if x > similarity_matrix[i][i]])\n",
    "            reciprocal_rank = 1 / (label_rank + 1)\n",
    "            total_mrr += reciprocal_rank\n",
    "\n",
    "            # Record predictions and labels\n",
    "            predictions = [0 if sim < threshold else 1 for sim in similarity_matrix[i]]\n",
    "            total_labels.extend([0 if k != i else 1 for k in range(len(similarity_matrix[i]))])\n",
    "            total_predictions.extend(predictions)\n",
    "            if label_similarity >= threshold:\n",
    "                number_of_golden_predictions += 1\n",
    "\n",
    "            total_instances += 1\n",
    "\n",
    "\n",
    "        # Compute average metrics over all instances\n",
    "        avg_hits_1 = total_hits_1 / total_instances\n",
    "        avg_mrr = total_mrr / total_instances\n",
    "        precision = precision_score(total_labels, total_predictions, average='macro')\n",
    "        recall = recall_score(total_labels, total_predictions, average='macro')\n",
    "        f1 = f1_score(total_labels, total_predictions, average='macro')\n",
    "        precision_micro = precision_score(total_labels, total_predictions, average='micro')\n",
    "        recall_micro = recall_score(total_labels, total_predictions, average='micro')\n",
    "        f1_micro = f1_score(total_labels, total_predictions, average='micro')\n",
    "        accuracy = accuracy_score(total_labels, total_predictions)\n",
    "        golden_prediction_accuracy = number_of_golden_predictions / total_instances\n",
    "\n",
    "        return {\n",
    "            'Hits@1': avg_hits_1,\n",
    "            'MRR': avg_mrr,\n",
    "            'Macro Precision': precision,\n",
    "            'Macro Recall': recall,\n",
    "            'Macro F1': f1,\n",
    "            'Micro Precision': precision_micro,\n",
    "            'Micro Recall': recall_micro,\n",
    "            'Micro F1': f1_micro,\n",
    "            'Accuracy': accuracy,\n",
    "            'Golden Accuracy': golden_prediction_accuracy,\n",
    "        }\n",
    "    \n",
    "    results = _evaluate(similarity_matrix, threshold=threshold)\n",
    "    table = []\n",
    "    for i in range(len(results)):\n",
    "        table.append([list(results.keys())[i], list(results.values())[i]])\n",
    "    print(tabulate(table, ['Metrics', 'Values'], tablefmt=\"grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T23:56:56.845223Z",
     "iopub.status.busy": "2024-01-04T23:56:56.844274Z",
     "iopub.status.idle": "2024-01-05T00:25:34.689115Z",
     "shell.execute_reply": "2024-01-05T00:25:34.688102Z",
     "shell.execute_reply.started": "2024-01-04T23:56:56.845189Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11411/11411 [00:50<00:00, 225.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+\n",
      "| Metrics         |   Values |\n",
      "+=================+==========+\n",
      "| Hits@1          | 0.901937 |\n",
      "+-----------------+----------+\n",
      "| MRR             | 0.940338 |\n",
      "+-----------------+----------+\n",
      "| Macro Precision | 0.610473 |\n",
      "+-----------------+----------+\n",
      "| Macro Recall    | 0.972293 |\n",
      "+-----------------+----------+\n",
      "| Macro F1        | 0.679002 |\n",
      "+-----------------+----------+\n",
      "| Micro Precision | 0.999703 |\n",
      "+-----------------+----------+\n",
      "| Micro Recall    | 0.999703 |\n",
      "+-----------------+----------+\n",
      "| Micro F1        | 0.999703 |\n",
      "+-----------------+----------+\n",
      "| Accuracy        | 0.999703 |\n",
      "+-----------------+----------+\n",
      "| Golden Accuracy | 0.944878 |\n",
      "+-----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "evaluate(similarity_matrix, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('hubert_labse_model_es.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hard Evaluation based on sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T17:10:27.725963Z",
     "iopub.status.busy": "2024-10-29T17:10:27.725595Z",
     "iopub.status.idle": "2024-10-29T17:10:27.732310Z",
     "shell.execute_reply": "2024-10-29T17:10:27.731397Z",
     "shell.execute_reply.started": "2024-10-29T17:10:27.725931Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CusDataset(Dataset):\n",
    "    def __init__(self, dataset, audio_name, text_name):\n",
    "        self.dataset = dataset\n",
    "        self.text_name = text_name\n",
    "        self.audio_name = audio_name\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset[self.audio_name])\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.dataset[self.text_name][i], self.dataset[self.audio_name][i], self.dataset['image'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T11:06:15.953498Z",
     "iopub.status.busy": "2024-08-10T11:06:15.953085Z",
     "iopub.status.idle": "2024-08-10T11:06:15.969057Z",
     "shell.execute_reply": "2024-08-10T11:06:15.968272Z",
     "shell.execute_reply.started": "2024-08-10T11:06:15.953465Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, average_precision_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "def evaluate_matrix(similarity_matrix, sources, threshold=0.5):\n",
    "    \n",
    "    def _evaluate(similarity_matrix, indices, threshold=0.5):\n",
    "        total_hits_1 = 0\n",
    "        total_mrr = 0\n",
    "        total_instances = 0\n",
    "        total_labels = []\n",
    "        total_predictions = []\n",
    "        number_of_golden_predictions = 0\n",
    "        total_ap = 0\n",
    "        total_recall_5 = 0\n",
    "        total_rank = 0\n",
    "\n",
    "        for i in tqdm(indices):\n",
    "            predicted_idx = np.argmax(similarity_matrix[i])\n",
    "            label_similarity = similarity_matrix[i][i]\n",
    "\n",
    "            if predicted_idx != i and similarity_matrix[i][predicted_idx] == label_similarity: \n",
    "                continue\n",
    "\n",
    "            # Compute Hits@1\n",
    "            if predicted_idx == i:   \n",
    "                total_hits_1 += 1 \n",
    "\n",
    "            total_instances += 1\n",
    "\n",
    "            # Compute MRR\n",
    "            label_rank = sum([1 for x in similarity_matrix[i] if x > similarity_matrix[i][i]])\n",
    "            reciprocal_rank = 1 / (label_rank + 1)\n",
    "            total_mrr += reciprocal_rank\n",
    "\n",
    "            # Compute meanR\n",
    "            total_rank += (label_rank + 1)\n",
    "            \n",
    "\n",
    "            # Record predictions and labels\n",
    "            predictions = [0 if sim < threshold else 1 for sim in similarity_matrix[i]]\n",
    "            total_labels.extend([0 if k != i else 1 for k in range(len(similarity_matrix[i]))])\n",
    "            total_predictions.extend(predictions)\n",
    "            if label_similarity >= threshold:\n",
    "                number_of_golden_predictions += 1\n",
    "            \n",
    "            \n",
    "        print(total_instances)\n",
    "        # Compute average metrics over all instances\n",
    "        avg_hits_1 = total_hits_1 / total_instances\n",
    "        avg_mrr = total_mrr / total_instances\n",
    "        avg_rank = total_rank / total_instances\n",
    "        f1 = f1_score(total_labels, total_predictions, average='macro')\n",
    "        golden_prediction_accuracy = number_of_golden_predictions / total_instances\n",
    "\n",
    "\n",
    "        return {\n",
    "            'Hits@1': avg_hits_1,\n",
    "            'MRR': avg_mrr,\n",
    "            'meanR': avg_rank,\n",
    "            'Macro F1': f1,\n",
    "            'Golden Accuracy': golden_prediction_accuracy,\n",
    "        }\n",
    "\n",
    "    # Create a dictionary to store metrics for each source\n",
    "    source_metrics = defaultdict(dict)\n",
    "    \n",
    "    # Get unique sources\n",
    "    unique_sources = set(sources)\n",
    "    \n",
    "    # Evaluate metrics for each source\n",
    "    for source in unique_sources:\n",
    "        print(source)\n",
    "        indices = [i for i, s in enumerate(sources) if s == source]\n",
    "        source_metrics[source] = _evaluate(similarity_matrix, indices, threshold=threshold)\n",
    "    \n",
    "    # Print the metrics for each source\n",
    "    for source, metrics in source_metrics.items():\n",
    "        print(f\"Metrics for source {source}:\")\n",
    "        table = []\n",
    "        for metric, value in metrics.items():\n",
    "            table.append([metric, value])\n",
    "        print(tabulate(table, ['Metrics', 'Values'], tablefmt=\"grid\"))\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Example usage\n",
    "# similarity_matrix = ... (your similarity matrix)\n",
    "# sources = ... (your list of sources)\n",
    "# evaluate_matrix(similarity_matrix, sources, threshold=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T11:33:36.228040Z",
     "iopub.status.busy": "2024-08-10T11:33:36.227660Z",
     "iopub.status.idle": "2024-08-10T11:33:47.527353Z",
     "shell.execute_reply": "2024-08-10T11:33:47.526531Z",
     "shell.execute_reply.started": "2024-08-10T11:33:36.228010Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_name = 'hubert_labse_model_es'  \n",
    "with open(f'similarity_matrix_{model_name}.pkl', 'rb') as f:\n",
    "    similarity_matrix = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T13:42:35.233707Z",
     "iopub.status.busy": "2024-08-08T13:42:35.233268Z",
     "iopub.status.idle": "2024-08-08T13:42:35.241112Z",
     "shell.execute_reply": "2024-08-08T13:42:35.239987Z",
     "shell.execute_reply.started": "2024-08-08T13:42:35.233671Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'common_voice'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_dataset['test']['source'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T11:06:25.323122Z",
     "iopub.status.busy": "2024-08-10T11:06:25.322753Z",
     "iopub.status.idle": "2024-08-10T11:11:19.068159Z",
     "shell.execute_reply": "2024-08-10T11:11:19.067207Z",
     "shell.execute_reply.started": "2024-08-10T11:06:25.323091Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8567/8567 [00:36<00:00, 237.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8519\n",
      "fleurs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 647/647 [00:01<00:00, 355.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353\n",
      "common_voice\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2197/2197 [00:09<00:00, 229.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2193\n",
      "Metrics for source brown:\n",
      "+-----------------+----------+\n",
      "| Metrics         |   Values |\n",
      "+=================+==========+\n",
      "| Hits@1          | 0.944829 |\n",
      "+-----------------+----------+\n",
      "| MRR             | 0.959491 |\n",
      "+-----------------+----------+\n",
      "| meanR           | 3.69292  |\n",
      "+-----------------+----------+\n",
      "| Macro F1        | 0.713267 |\n",
      "+-----------------+----------+\n",
      "| Golden Accuracy | 0.854795 |\n",
      "+-----------------+----------+\n",
      "\n",
      "\n",
      "Metrics for source fleurs:\n",
      "+-----------------+----------+\n",
      "| Metrics         |   Values |\n",
      "+=================+==========+\n",
      "| Hits@1          | 0.974504 |\n",
      "+-----------------+----------+\n",
      "| MRR             | 0.982082 |\n",
      "+-----------------+----------+\n",
      "| meanR           | 1.16431  |\n",
      "+-----------------+----------+\n",
      "| Macro F1        | 0.80359  |\n",
      "+-----------------+----------+\n",
      "| Golden Accuracy | 0.76204  |\n",
      "+-----------------+----------+\n",
      "\n",
      "\n",
      "Metrics for source common_voice:\n",
      "+-----------------+-----------+\n",
      "| Metrics         |    Values |\n",
      "+=================+===========+\n",
      "| Hits@1          |  0.915641 |\n",
      "+-----------------+-----------+\n",
      "| MRR             |  0.934944 |\n",
      "+-----------------+-----------+\n",
      "| meanR           | 24.3675   |\n",
      "+-----------------+-----------+\n",
      "| Macro F1        |  0.691829 |\n",
      "+-----------------+-----------+\n",
      "| Golden Accuracy |  0.843593 |\n",
      "+-----------------+-----------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_matrix(similarity_matrix, total_dataset['test']['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T11:39:25.419032Z",
     "iopub.status.busy": "2024-08-10T11:39:25.418072Z",
     "iopub.status.idle": "2024-08-10T11:39:37.670143Z",
     "shell.execute_reply": "2024-08-10T11:39:37.669300Z",
     "shell.execute_reply.started": "2024-08-10T11:39:25.418994Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open('similarity_matrix_hubert_asr.pkl', 'rb') as f:\n",
    "    similarity_matrix2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T11:13:29.451679Z",
     "iopub.status.busy": "2024-08-10T11:13:29.451400Z",
     "iopub.status.idle": "2024-08-10T11:18:29.772522Z",
     "shell.execute_reply": "2024-08-10T11:18:29.771455Z",
     "shell.execute_reply.started": "2024-08-10T11:13:29.451655Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8567/8567 [00:36<00:00, 234.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8547\n",
      "fleurs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 647/647 [00:01<00:00, 329.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n",
      "common_voice\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2197/2197 [00:09<00:00, 230.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2194\n",
      "Metrics for source brown:\n",
      "+-----------------+-----------+\n",
      "| Metrics         |    Values |\n",
      "+=================+===========+\n",
      "| Hits@1          |  0.947584 |\n",
      "+-----------------+-----------+\n",
      "| MRR             |  0.958399 |\n",
      "+-----------------+-----------+\n",
      "| meanR           | 20.4336   |\n",
      "+-----------------+-----------+\n",
      "| Macro F1        |  0.704701 |\n",
      "+-----------------+-----------+\n",
      "| Golden Accuracy |  0.970867 |\n",
      "+-----------------+-----------+\n",
      "\n",
      "\n",
      "Metrics for source fleurs:\n",
      "+-----------------+----------+\n",
      "| Metrics         |   Values |\n",
      "+=================+==========+\n",
      "| Hits@1          | 1        |\n",
      "+-----------------+----------+\n",
      "| MRR             | 1        |\n",
      "+-----------------+----------+\n",
      "| meanR           | 1        |\n",
      "+-----------------+----------+\n",
      "| Macro F1        | 0.781316 |\n",
      "+-----------------+----------+\n",
      "| Golden Accuracy | 1        |\n",
      "+-----------------+----------+\n",
      "\n",
      "\n",
      "Metrics for source common_voice:\n",
      "+-----------------+-----------+\n",
      "| Metrics         |    Values |\n",
      "+=================+===========+\n",
      "| Hits@1          |  0.968095 |\n",
      "+-----------------+-----------+\n",
      "| MRR             |  0.973916 |\n",
      "+-----------------+-----------+\n",
      "| meanR           | 10.4216   |\n",
      "+-----------------+-----------+\n",
      "| Macro F1        |  0.616491 |\n",
      "+-----------------+-----------+\n",
      "| Golden Accuracy |  0.969462 |\n",
      "+-----------------+-----------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_matrix(similarity_matrix2, total_dataset['test']['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T11:48:27.559264Z",
     "iopub.status.busy": "2024-08-10T11:48:27.558885Z",
     "iopub.status.idle": "2024-08-10T11:48:38.682328Z",
     "shell.execute_reply": "2024-08-10T11:48:38.681508Z",
     "shell.execute_reply.started": "2024-08-10T11:48:27.559233Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open('similarity_matrix_wav2vec2_asr.pkl', 'rb') as f:\n",
    "    similarity_matrix3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T11:20:15.569421Z",
     "iopub.status.busy": "2024-08-10T11:20:15.568748Z",
     "iopub.status.idle": "2024-08-10T11:25:16.280090Z",
     "shell.execute_reply": "2024-08-10T11:25:16.279194Z",
     "shell.execute_reply.started": "2024-08-10T11:20:15.569384Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8567/8567 [00:36<00:00, 232.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8552\n",
      "fleurs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 647/647 [00:01<00:00, 330.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351\n",
      "common_voice\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2197/2197 [00:09<00:00, 230.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2194\n",
      "Metrics for source brown:\n",
      "+-----------------+-----------+\n",
      "| Metrics         |    Values |\n",
      "+=================+===========+\n",
      "| Hits@1          |  0.934167 |\n",
      "+-----------------+-----------+\n",
      "| MRR             |  0.944619 |\n",
      "+-----------------+-----------+\n",
      "| meanR           | 37.2572   |\n",
      "+-----------------+-----------+\n",
      "| Macro F1        |  0.696978 |\n",
      "+-----------------+-----------+\n",
      "| Golden Accuracy |  0.955215 |\n",
      "+-----------------+-----------+\n",
      "\n",
      "\n",
      "Metrics for source fleurs:\n",
      "+-----------------+----------+\n",
      "| Metrics         |   Values |\n",
      "+=================+==========+\n",
      "| Hits@1          | 0.994302 |\n",
      "+-----------------+----------+\n",
      "| MRR             | 0.994338 |\n",
      "+-----------------+----------+\n",
      "| meanR           | 1.90028  |\n",
      "+-----------------+----------+\n",
      "| Macro F1        | 0.793493 |\n",
      "+-----------------+----------+\n",
      "| Golden Accuracy | 0.994302 |\n",
      "+-----------------+----------+\n",
      "\n",
      "\n",
      "Metrics for source common_voice:\n",
      "+-----------------+-----------+\n",
      "| Metrics         |    Values |\n",
      "+=================+===========+\n",
      "| Hits@1          |  0.890611 |\n",
      "+-----------------+-----------+\n",
      "| MRR             |  0.906474 |\n",
      "+-----------------+-----------+\n",
      "| meanR           | 48.1878   |\n",
      "+-----------------+-----------+\n",
      "| Macro F1        |  0.619894 |\n",
      "+-----------------+-----------+\n",
      "| Golden Accuracy |  0.889243 |\n",
      "+-----------------+-----------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_matrix(similarity_matrix3, total_dataset['test']['source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation after removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T16:57:46.505001Z",
     "iopub.status.busy": "2024-10-29T16:57:46.504624Z",
     "iopub.status.idle": "2024-10-29T16:57:46.518389Z",
     "shell.execute_reply": "2024-10-29T16:57:46.517465Z",
     "shell.execute_reply.started": "2024-10-29T16:57:46.504970Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, average_precision_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "def evaluate_matrix_full(similarity_matrix, threshold=0.5):\n",
    "    \n",
    "    def _evaluate(similarity_matrix, threshold=0.5):\n",
    "        total_hits_1 = 0\n",
    "        total_mrr = 0\n",
    "        total_instances = 0\n",
    "        total_labels = []\n",
    "        total_predictions = []\n",
    "        number_of_golden_predictions = 0\n",
    "        total_ap = 0\n",
    "        total_recall_5 = 0\n",
    "        total_rank = 0\n",
    "\n",
    "        for i in tqdm(range(len(similarity_matrix))):\n",
    "            predicted_idx = np.argmax(similarity_matrix[i])\n",
    "            label_similarity = similarity_matrix[i][i]\n",
    "\n",
    "            if predicted_idx != i and similarity_matrix[i][predicted_idx] == label_similarity: \n",
    "                continue\n",
    "\n",
    "            # Compute Hits@1\n",
    "            if predicted_idx == i:   \n",
    "                total_hits_1 += 1 \n",
    "\n",
    "            total_instances += 1\n",
    "\n",
    "            # Compute MRR\n",
    "            label_rank = sum([1 for x in similarity_matrix[i] if x > similarity_matrix[i][i]])\n",
    "            reciprocal_rank = 1 / (label_rank + 1)\n",
    "            total_mrr += reciprocal_rank\n",
    "\n",
    "            # Compute meanR\n",
    "            total_rank += (label_rank + 1)\n",
    "            \n",
    "\n",
    "            # Record predictions and labels\n",
    "            predictions = [0 if sim < threshold else 1 for sim in similarity_matrix[i]]\n",
    "            total_labels.extend([0 if k != i else 1 for k in range(len(similarity_matrix[i]))])\n",
    "            total_predictions.extend(predictions)\n",
    "            if label_similarity >= threshold:\n",
    "                number_of_golden_predictions += 1\n",
    "            \n",
    "            \n",
    "        print(total_instances)\n",
    "        # Compute average metrics over all instances\n",
    "        avg_hits_1 = total_hits_1 / total_instances\n",
    "        avg_mrr = total_mrr / total_instances\n",
    "        avg_rank = total_rank / total_instances\n",
    "        f1 = f1_score(total_labels, total_predictions, average='macro')\n",
    "        golden_prediction_accuracy = number_of_golden_predictions / total_instances\n",
    "\n",
    "\n",
    "        return {\n",
    "            'Hits@1': avg_hits_1,\n",
    "            'MRR': avg_mrr,\n",
    "            'meanR': avg_rank,\n",
    "            'Macro F1': f1,\n",
    "            'Golden Accuracy': golden_prediction_accuracy,\n",
    "        }\n",
    "\n",
    "    results = _evaluate(similarity_matrix, threshold=threshold)\n",
    "    table = []\n",
    "    for i in range(len(results)):\n",
    "        table.append([list(results.keys())[i], list(results.values())[i]])\n",
    "    print(tabulate(table, ['Metrics', 'Values'], tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T11:33:47.561495Z",
     "iopub.status.busy": "2024-08-10T11:33:47.560824Z",
     "iopub.status.idle": "2024-08-10T11:38:40.193519Z",
     "shell.execute_reply": "2024-08-10T11:38:40.191906Z",
     "shell.execute_reply.started": "2024-08-10T11:33:47.561459Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11411/11411 [00:47<00:00, 242.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11065\n",
      "+-----------------+----------+\n",
      "| Metrics         |   Values |\n",
      "+=================+==========+\n",
      "| Hits@1          | 0.939991 |\n",
      "+-----------------+----------+\n",
      "| MRR             | 0.955346 |\n",
      "+-----------------+----------+\n",
      "| meanR           | 7.70981  |\n",
      "+-----------------+----------+\n",
      "| Macro F1        | 0.710431 |\n",
      "+-----------------+----------+\n",
      "| Golden Accuracy | 0.849616 |\n",
      "+-----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "evaluate_matrix_full(similarity_matrix, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T11:39:37.672150Z",
     "iopub.status.busy": "2024-08-10T11:39:37.671849Z",
     "iopub.status.idle": "2024-08-10T11:44:30.500241Z",
     "shell.execute_reply": "2024-08-10T11:44:30.499194Z",
     "shell.execute_reply.started": "2024-08-10T11:39:37.672124Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11411/11411 [00:47<00:00, 241.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11091\n",
      "+-----------------+-----------+\n",
      "| Metrics         |    Values |\n",
      "+=================+===========+\n",
      "| Hits@1          |  0.953295 |\n",
      "+-----------------+-----------+\n",
      "| MRR             |  0.962781 |\n",
      "+-----------------+-----------+\n",
      "| meanR           | 17.8398   |\n",
      "+-----------------+-----------+\n",
      "| Macro F1        |  0.679489 |\n",
      "+-----------------+-----------+\n",
      "| Golden Accuracy |  0.971508 |\n",
      "+-----------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "evaluate_matrix_full(similarity_matrix2, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T11:48:47.925829Z",
     "iopub.status.busy": "2024-08-10T11:48:47.925471Z",
     "iopub.status.idle": "2024-08-10T11:53:46.661708Z",
     "shell.execute_reply": "2024-08-10T11:53:46.660511Z",
     "shell.execute_reply.started": "2024-08-10T11:48:47.925802Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11411/11411 [00:48<00:00, 233.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11097\n",
      "+-----------------+-----------+\n",
      "| Metrics         |    Values |\n",
      "+=================+===========+\n",
      "| Hits@1          |  0.927458 |\n",
      "+-----------------+-----------+\n",
      "| MRR             |  0.93865  |\n",
      "+-----------------+-----------+\n",
      "| meanR           | 38.3      |\n",
      "+-----------------+-----------+\n",
      "| Macro F1        |  0.677658 |\n",
      "+-----------------+-----------+\n",
      "| Golden Accuracy |  0.943408 |\n",
      "+-----------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "evaluate_matrix_full(similarity_matrix3, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'lasp_concat'  \n",
    "with open(f'similarity_matrix_{model_name}.pkl', 'rb') as f:\n",
    "    similarity_matrix = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11411/11411 [00:48<00:00, 236.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11097\n",
      "+-----------------+----------+\n",
      "| Metrics         |   Values |\n",
      "+=================+==========+\n",
      "| Hits@1          | 0.877715 |\n",
      "+-----------------+----------+\n",
      "| MRR             | 0.90887  |\n",
      "+-----------------+----------+\n",
      "| meanR           | 9.09228  |\n",
      "+-----------------+----------+\n",
      "| Macro F1        | 0.533584 |\n",
      "+-----------------+----------+\n",
      "| Golden Accuracy | 0.969451 |\n",
      "+-----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "evaluate_matrix_full(similarity_matrix, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T12:05:55.051251Z",
     "iopub.status.busy": "2024-08-10T12:05:55.050867Z",
     "iopub.status.idle": "2024-08-10T12:05:55.057977Z",
     "shell.execute_reply": "2024-08-10T12:05:55.056804Z",
     "shell.execute_reply.started": "2024-08-10T12:05:55.051218Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['audio', 'text', 'image', 'xlmr-emb', 'hubert-emb', 'pure-text', 'id', 'source', 'audio_path'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_dataset['test'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T12:13:28.688617Z",
     "iopub.status.busy": "2024-08-10T12:13:28.688229Z",
     "iopub.status.idle": "2024-08-10T12:13:28.697004Z",
     "shell.execute_reply": "2024-08-10T12:13:28.696089Z",
     "shell.execute_reply.started": "2024-08-10T12:13:28.688586Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11056"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(total_dataset['test']['pure-text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T12:15:41.525142Z",
     "iopub.status.busy": "2024-08-10T12:15:41.524791Z",
     "iopub.status.idle": "2024-08-10T12:15:41.537678Z",
     "shell.execute_reply": "2024-08-10T12:15:41.536579Z",
     "shell.execute_reply.started": "2024-08-10T12:15:41.525117Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: common_voice, Unique 'pure_text' count: 2193\n",
      "Source: brown, Unique 'pure_text' count: 8513\n",
      "Source: fleurs, Unique 'pure_text' count: 350\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Assuming total_dataset is a dictionary and 'test' is a key in that dictionary\n",
    "# and 'pure_text' and 'sources' are keys in the 'test' dataset\n",
    "\n",
    "# Extract the 'pure_text' and 'sources' values\n",
    "pure_text_values = total_dataset['test']['pure-text']\n",
    "sources_values = total_dataset['test']['source']\n",
    "\n",
    "# Create a dictionary to store unique counts for each source\n",
    "unique_counts_by_source = defaultdict(set)\n",
    "\n",
    "# Iterate through the dataset and count unique 'pure_text' values for each source\n",
    "for text, source in zip(pure_text_values, sources_values):\n",
    "    unique_counts_by_source[source].add(text)\n",
    "\n",
    "# Convert sets to counts\n",
    "unique_counts_by_source = {source: len(texts) for source, texts in unique_counts_by_source.items()}\n",
    "\n",
    "# Print the unique counts for each source\n",
    "for source, count in unique_counts_by_source.items():\n",
    "    print(f\"Source: {source}, Unique 'pure_text' count: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T12:16:32.954157Z",
     "iopub.status.busy": "2024-08-10T12:16:32.953218Z",
     "iopub.status.idle": "2024-08-10T12:16:32.959956Z",
     "shell.execute_reply": "2024-08-10T12:16:32.959012Z",
     "shell.execute_reply.started": "2024-08-10T12:16:32.954125Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11411 - 11056"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T12:20:53.027014Z",
     "iopub.status.busy": "2024-08-10T12:20:53.026082Z",
     "iopub.status.idle": "2024-08-10T12:20:53.032934Z",
     "shell.execute_reply": "2024-08-10T12:20:53.032020Z",
     "shell.execute_reply.started": "2024-08-10T12:20:53.026976Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='total_dataset_v11.pkl' target='_blank'>total_dataset_v11.pkl</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/total_dataset_v11.pkl"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('total_dataset_v11.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilingaul Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T17:07:01.463048Z",
     "iopub.status.busy": "2024-10-29T17:07:01.462684Z",
     "iopub.status.idle": "2024-10-29T17:07:13.271238Z",
     "shell.execute_reply": "2024-10-29T17:07:13.270412Z",
     "shell.execute_reply.started": "2024-10-29T17:07:01.463021Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1-3-mpLSKuUaYjstN4ZE88pg06rEisEoh\n",
      "From (redirected): https://drive.google.com/uc?id=1-3-mpLSKuUaYjstN4ZE88pg06rEisEoh&confirm=t&uuid=3799f763-b2f9-4fb9-96b5-9ed714fddd74\n",
      "To: /kaggle/working/translated-text-embeddings-test-fa.pkl\n",
      "100%|██████████| 1.12G/1.12G [00:07<00:00, 143MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'translated-text-embeddings-test-fa.pkl'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://drive.google.com/file/d/1-3-mpLSKuUaYjstN4ZE88pg06rEisEoh/view?usp=sharing\"\n",
    "output = \"translated-text-embeddings-test-fa.pkl\"\n",
    "gdown.download(url, output, quiet=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T17:08:34.868474Z",
     "iopub.status.busy": "2024-10-29T17:08:34.868151Z",
     "iopub.status.idle": "2024-10-29T17:08:34.910916Z",
     "shell.execute_reply": "2024-10-29T17:08:34.909808Z",
     "shell.execute_reply.started": "2024-10-29T17:08:34.868446Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset = total_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T17:10:34.429033Z",
     "iopub.status.busy": "2024-10-29T17:10:34.428336Z",
     "iopub.status.idle": "2024-10-29T17:10:35.456671Z",
     "shell.execute_reply": "2024-10-29T17:10:35.455724Z",
     "shell.execute_reply.started": "2024-10-29T17:10:34.428999Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 357/357 [00:00<00:00, 462.05it/s]\n"
     ]
    }
   ],
   "source": [
    "model_to_test = torch.load(f'hubert_labse_model_es.pt', map_location=device)\n",
    "model_to_test = model_to_test.to(device)\n",
    "test_dataloader = DataLoader(dataset=CusDataset(dataset, 'hubert-emb', 'text'), batch_size=32, shuffle=False)\n",
    "dataset['clasp_emb'] = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for text_embedding, audio_candidates, image_candidates in tqdm(test_dataloader):\n",
    "        audio_candidates = audio_candidates.to(device)\n",
    "        image_candidates = image_candidates.to(device)\n",
    "        final_emb = model_to_test(audio_candidates, image_candidates)\n",
    "        dataset['clasp_emb'].extend(final_emb)\n",
    "\n",
    "for i in range(len(dataset['clasp_emb'])):\n",
    "    dataset['clasp_emb'][i] = dataset['clasp_emb'][i].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T13:05:42.924092Z",
     "iopub.status.busy": "2024-10-27T13:05:42.923704Z",
     "iopub.status.idle": "2024-10-27T13:05:42.935009Z",
     "shell.execute_reply": "2024-10-27T13:05:42.934238Z",
     "shell.execute_reply.started": "2024-10-27T13:05:42.924062Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_similarity_matrix(dataset, target_lang):\n",
    "    with open(f'translated-text-embeddings-test-{target_lang}.pkl', 'rb') as f:\n",
    "        dataset['translated-text-embeddings'] = pickle.load(f)\n",
    "\n",
    "    similarity_dataset = {}\n",
    "    similarity_dataset['clasp_emb'] = dataset['clasp_emb']\n",
    "    similarity_dataset['text'] = dataset['translated-text-embeddings']\n",
    "\n",
    "    similarity_matrix = []\n",
    "    for i in tqdm(range(len(similarity_dataset['text']))):\n",
    "        similarity_matrix.append([])\n",
    "        for j in range(len(similarity_dataset['clasp_emb'])):\n",
    "            similarity_matrix[i].append(cosine_similarity(similarity_dataset['text'][i].unsqueeze(0), similarity_dataset['clasp_emb'][j].unsqueeze(0)).item())\n",
    "\n",
    "    with open(f'similarity_matrix_{target_lang}.pkl', 'wb') as f:\n",
    "        pickle.dump(similarity_matrix, f)\n",
    "    \n",
    "    with open('target_lang.txt', 'w') as f:\n",
    "        f.write(f'{target_lang}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T13:05:59.435805Z",
     "iopub.status.busy": "2024-10-27T13:05:59.435401Z",
     "iopub.status.idle": "2024-10-27T16:11:36.542727Z",
     "shell.execute_reply": "2024-10-27T16:11:36.541665Z",
     "shell.execute_reply.started": "2024-10-27T13:05:59.435770Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11411/11411 [3:05:27<00:00,  1.03it/s] \n"
     ]
    }
   ],
   "source": [
    "create_similarity_matrix(dataset, 'fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T16:14:48.762795Z",
     "iopub.status.busy": "2024-10-27T16:14:48.762382Z",
     "iopub.status.idle": "2024-10-27T16:20:10.684566Z",
     "shell.execute_reply": "2024-10-27T16:20:10.683410Z",
     "shell.execute_reply.started": "2024-10-27T16:14:48.762761Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11411/11411 [00:49<00:00, 232.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11411\n",
      "+-----------------+-----------+\n",
      "| Metrics         |    Values |\n",
      "+=================+===========+\n",
      "| Hits@1          |  0.794409 |\n",
      "+-----------------+-----------+\n",
      "| MRR             |  0.848206 |\n",
      "+-----------------+-----------+\n",
      "| meanR           | 26.9598   |\n",
      "+-----------------+-----------+\n",
      "| Macro F1        |  0.670136 |\n",
      "+-----------------+-----------+\n",
      "| Golden Accuracy |  0.322671 |\n",
      "+-----------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "with open(f'similarity_matrix_fa.pkl', 'rb') as f:\n",
    "    similarity_matrix_lg = pickle.load(f)\n",
    "evaluate_matrix_full(similarity_matrix_lg, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T16:22:05.302260Z",
     "iopub.status.busy": "2024-10-27T16:22:05.301353Z",
     "iopub.status.idle": "2024-10-27T16:22:19.977846Z",
     "shell.execute_reply": "2024-10-27T16:22:19.976623Z",
     "shell.execute_reply.started": "2024-10-27T16:22:05.302225Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1jHNsQh1-QwRevXbw7G4JH0BT7rVeOD6t\n",
      "From (redirected): https://drive.google.com/uc?id=1jHNsQh1-QwRevXbw7G4JH0BT7rVeOD6t&confirm=t&uuid=39a1786e-9262-4a07-b4c6-8f77ac7f8bc1\n",
      "To: /kaggle/working/translated-text-embeddings-test-de.pkl\n",
      "100%|██████████| 1.12G/1.12G [00:10<00:00, 105MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'translated-text-embeddings-test-de.pkl'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://drive.google.com/file/d/1jHNsQh1-QwRevXbw7G4JH0BT7rVeOD6t/view?usp=sharing\"\n",
    "output = \"translated-text-embeddings-test-de.pkl\"\n",
    "gdown.download(url, output, quiet=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T17:11:05.405944Z",
     "iopub.status.busy": "2024-10-29T17:11:05.404974Z",
     "iopub.status.idle": "2024-10-29T17:11:05.416553Z",
     "shell.execute_reply": "2024-10-29T17:11:05.415241Z",
     "shell.execute_reply.started": "2024-10-29T17:11:05.405901Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_similarity_matrix(dataset, target_lang):\n",
    "    # Load embeddings from file\n",
    "    with open(f'translated-text-embeddings-test-{target_lang}.pkl', 'rb') as f:\n",
    "        dataset['translated-text-embeddings'] = pickle.load(f)\n",
    "\n",
    "    # Extract embeddings into tensors for efficient batch processing\n",
    "    clasp_emb = torch.stack(dataset['clasp_emb'])  # Shape: (num_clasp, embedding_dim)\n",
    "    text_emb = torch.stack(dataset['translated-text-embeddings'])  # Shape: (num_text, embedding_dim)\n",
    "\n",
    "    # Normalize embeddings once to avoid repeated computation\n",
    "    clasp_emb = F.normalize(clasp_emb, p=2, dim=1)\n",
    "    text_emb = F.normalize(text_emb, p=2, dim=1)\n",
    "\n",
    "    # Compute cosine similarity using matrix multiplication\n",
    "    similarity_matrix = torch.mm(text_emb, clasp_emb.T).cpu().tolist()\n",
    "\n",
    "    # Save similarity matrix\n",
    "    with open(f'similarity_matrix_{target_lang}.pkl', 'wb') as f:\n",
    "        pickle.dump(similarity_matrix, f)\n",
    "\n",
    "    # Save target language information\n",
    "    with open('target_lang.txt', 'w') as f:\n",
    "        f.write(f'{target_lang}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T16:29:38.731591Z",
     "iopub.status.busy": "2024-10-27T16:29:38.730836Z",
     "iopub.status.idle": "2024-10-27T16:29:56.100478Z",
     "shell.execute_reply": "2024-10-27T16:29:56.097537Z",
     "shell.execute_reply.started": "2024-10-27T16:29:38.731559Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "create_similarity_matrix(dataset, 'de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T16:30:25.391863Z",
     "iopub.status.busy": "2024-10-27T16:30:25.391104Z",
     "iopub.status.idle": "2024-10-27T16:35:48.299686Z",
     "shell.execute_reply": "2024-10-27T16:35:48.298675Z",
     "shell.execute_reply.started": "2024-10-27T16:30:25.391825Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11411/11411 [00:49<00:00, 231.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11411\n",
      "+-----------------+-----------+\n",
      "| Metrics         |    Values |\n",
      "+=================+===========+\n",
      "| Hits@1          |  0.811761 |\n",
      "+-----------------+-----------+\n",
      "| MRR             |  0.863102 |\n",
      "+-----------------+-----------+\n",
      "| meanR           | 21.637    |\n",
      "+-----------------+-----------+\n",
      "| Macro F1        |  0.670901 |\n",
      "+-----------------+-----------+\n",
      "| Golden Accuracy |  0.286653 |\n",
      "+-----------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "with open(f'similarity_matrix_de.pkl', 'rb') as f:\n",
    "    similarity_matrix_lg = pickle.load(f)\n",
    "evaluate_matrix_full(similarity_matrix_lg, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T16:57:55.260417Z",
     "iopub.status.busy": "2024-10-27T16:57:55.259976Z",
     "iopub.status.idle": "2024-10-27T16:57:57.982967Z",
     "shell.execute_reply": "2024-10-27T16:57:57.981516Z",
     "shell.execute_reply.started": "2024-10-27T16:57:55.260383Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!rm translated-text-embeddings-test-de.pkl\n",
    "!rm translated-text-embeddings-test-fa.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T16:57:57.986370Z",
     "iopub.status.busy": "2024-10-27T16:57:57.986003Z",
     "iopub.status.idle": "2024-10-27T16:58:17.190415Z",
     "shell.execute_reply": "2024-10-27T16:58:17.189418Z",
     "shell.execute_reply.started": "2024-10-27T16:57:57.986337Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1--dkivt5LH-6eSxXcmlVWfwzOHCv9l-t\n",
      "From (redirected): https://drive.google.com/uc?id=1--dkivt5LH-6eSxXcmlVWfwzOHCv9l-t&confirm=t&uuid=a64094c1-c803-42ad-ab2b-c82f9d498921\n",
      "To: /kaggle/working/translated-text-embeddings-test-fr.pkl\n",
      "100%|██████████| 1.12G/1.12G [00:15<00:00, 73.9MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'translated-text-embeddings-test-fr.pkl'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://drive.google.com/file/d/1--dkivt5LH-6eSxXcmlVWfwzOHCv9l-t/view?usp=sharing\"\n",
    "output = \"translated-text-embeddings-test-fr.pkl\"\n",
    "gdown.download(url, output, quiet=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T17:22:36.786558Z",
     "iopub.status.busy": "2024-10-27T17:22:36.785709Z",
     "iopub.status.idle": "2024-10-27T17:22:52.602485Z",
     "shell.execute_reply": "2024-10-27T17:22:52.601525Z",
     "shell.execute_reply.started": "2024-10-27T17:22:36.786520Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1-2x8KsEkPVFJuzWEzJRcuNZvmxSrK3gS\n",
      "From (redirected): https://drive.google.com/uc?id=1-2x8KsEkPVFJuzWEzJRcuNZvmxSrK3gS&confirm=t&uuid=c3fc2526-88a1-4bbb-b8cc-1aa3855b1f7a\n",
      "To: /kaggle/working/translated-text-embeddings-test-zh.pkl\n",
      "100%|██████████| 1.12G/1.12G [00:11<00:00, 93.7MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'translated-text-embeddings-test-zh.pkl'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://drive.google.com/file/d/1-2x8KsEkPVFJuzWEzJRcuNZvmxSrK3gS/view?usp=sharing\"\n",
    "output = \"translated-text-embeddings-test-zh.pkl\"\n",
    "gdown.download(url, output, quiet=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T16:58:17.192493Z",
     "iopub.status.busy": "2024-10-27T16:58:17.192196Z",
     "iopub.status.idle": "2024-10-27T17:04:00.667760Z",
     "shell.execute_reply": "2024-10-27T17:04:00.666603Z",
     "shell.execute_reply.started": "2024-10-27T16:58:17.192467Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11411/11411 [00:51<00:00, 223.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11411\n",
      "+-----------------+-----------+\n",
      "| Metrics         |    Values |\n",
      "+=================+===========+\n",
      "| Hits@1          |  0.848655 |\n",
      "+-----------------+-----------+\n",
      "| MRR             |  0.891647 |\n",
      "+-----------------+-----------+\n",
      "| meanR           | 16.0997   |\n",
      "+-----------------+-----------+\n",
      "| Macro F1        |  0.717795 |\n",
      "+-----------------+-----------+\n",
      "| Golden Accuracy |  0.420997 |\n",
      "+-----------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "create_similarity_matrix(dataset, 'fr')\n",
    "with open(f'similarity_matrix_fr.pkl', 'rb') as f:\n",
    "    similarity_matrix_lg = pickle.load(f)\n",
    "evaluate_matrix_full(similarity_matrix_lg, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T17:22:31.470102Z",
     "iopub.status.busy": "2024-10-27T17:22:31.469682Z",
     "iopub.status.idle": "2024-10-27T17:22:32.905720Z",
     "shell.execute_reply": "2024-10-27T17:22:32.904391Z",
     "shell.execute_reply.started": "2024-10-27T17:22:31.470071Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!rm translated-text-embeddings-test-fr.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T17:22:54.431038Z",
     "iopub.status.busy": "2024-10-27T17:22:54.430673Z",
     "iopub.status.idle": "2024-10-27T17:28:35.195276Z",
     "shell.execute_reply": "2024-10-27T17:28:35.194249Z",
     "shell.execute_reply.started": "2024-10-27T17:22:54.431007Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11411/11411 [00:49<00:00, 230.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11411\n",
      "+-----------------+-----------+\n",
      "| Metrics         |    Values |\n",
      "+=================+===========+\n",
      "| Hits@1          |  0.822189 |\n",
      "+-----------------+-----------+\n",
      "| MRR             |  0.870778 |\n",
      "+-----------------+-----------+\n",
      "| meanR           | 27.1251   |\n",
      "+-----------------+-----------+\n",
      "| Macro F1        |  0.743045 |\n",
      "+-----------------+-----------+\n",
      "| Golden Accuracy |  0.518622 |\n",
      "+-----------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "create_similarity_matrix(dataset, 'zh')\n",
    "with open(f'similarity_matrix_zh.pkl', 'rb') as f:\n",
    "    similarity_matrix_lg = pickle.load(f)\n",
    "evaluate_matrix_full(similarity_matrix_lg, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T17:31:15.224666Z",
     "iopub.status.busy": "2024-10-27T17:31:15.224277Z",
     "iopub.status.idle": "2024-10-27T17:31:16.670185Z",
     "shell.execute_reply": "2024-10-27T17:31:16.668967Z",
     "shell.execute_reply.started": "2024-10-27T17:31:15.224635Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!rm translated-text-embeddings-test-zh.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T20:33:23.204996Z",
     "iopub.status.busy": "2024-10-30T20:33:23.204699Z",
     "iopub.status.idle": "2024-10-30T20:33:24.314669Z",
     "shell.execute_reply": "2024-10-30T20:33:24.312869Z",
     "shell.execute_reply.started": "2024-10-30T20:33:23.204970Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!rm similarity_matrix_fa.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T17:11:09.799883Z",
     "iopub.status.busy": "2024-10-29T17:11:09.799001Z",
     "iopub.status.idle": "2024-10-29T17:16:55.974760Z",
     "shell.execute_reply": "2024-10-29T17:16:55.973767Z",
     "shell.execute_reply.started": "2024-10-29T17:11:09.799847Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11411/11411 [00:48<00:00, 232.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11411\n",
      "+-----------------+-----------+\n",
      "| Metrics         |    Values |\n",
      "+=================+===========+\n",
      "| Hits@1          |  0.794409 |\n",
      "+-----------------+-----------+\n",
      "| MRR             |  0.848206 |\n",
      "+-----------------+-----------+\n",
      "| meanR           | 26.9598   |\n",
      "+-----------------+-----------+\n",
      "| Macro F1        |  0.670136 |\n",
      "+-----------------+-----------+\n",
      "| Golden Accuracy |  0.322671 |\n",
      "+-----------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "create_similarity_matrix(dataset, 'fa')\n",
    "with open(f'similarity_matrix_fa.pkl', 'rb') as f:\n",
    "    similarity_matrix_lg = pickle.load(f)\n",
    "evaluate_matrix_full(similarity_matrix_lg, threshold=0.5)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30559,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
